<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Laurent U Perrinet | CONECT | Computational Neuroscience Center @ INT</title>
    <link>https://conect-int.github.io/authors/laurent-u-perrinet/</link>
      <atom:link href="https://conect-int.github.io/authors/laurent-u-perrinet/index.xml" rel="self" type="application/rss+xml" />
    <description>Laurent U Perrinet</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 20 Jun 2023 14:00:00 +0000</lastBuildDate>
    <image>
      <url>https://conect-int.github.io/authors/laurent-u-perrinet/avatar_hufdd75f582622d56af8f81b6f2821d19b_501026_270x270_fill_lanczos_center_3.png</url>
      <title>Laurent U Perrinet</title>
      <link>https://conect-int.github.io/authors/laurent-u-perrinet/</link>
    </image>
    
    <item>
      <title>Why CONECT?</title>
      <link>https://conect-int.github.io/post/about-conect/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/post/about-conect/</guid>
      <description>&lt;p&gt;Neuroscience is in revolution: Over the past decade, tremendous technological advances across several disciplines have dramatically expanded the frontiers of experimentally accessible neuroscientific facts.&lt;/p&gt;
&lt;p&gt;Bridging across different spatial and temporal scales, combination of in vivo two photon imaging, large population recording-array technologies, optogenetic circuit control tools, transgenic manipulations as well as large volume circuit reconstructions are now used to examine the function, structure and dynamics of neural networks on an unprecedented level of detail and precision. Current applications of these novel techniques include sensory information processing, motor production, neural correlates of learning, memory and decision making as well as mechanisms of dysfunctions and disease. These experiments have begun to produce a huge amount of data, on a broad spectrum of temporal and spatial scales, providing finer and more quantitative descriptions of the biological reality than we would have been able to dream of only a decade ago. The daunting complexity of the biological reality revealed by these technologies highlights the importance of neurophysics to provide a conceptual bridge between abstract principles of brain function and their biological implementations within neural circuits. This revolution is accompanied by a parallel revolution in the domain of Artificial Intelligence. An exponential number of algorithms in sensory processing, such as image classification, or reinforcement learning have realized practical tools which have replaced the classical tools we were using on a daily basis by a novel range of intelligent tools of a new generation. This is the context in which we are creating CONECT.&lt;/p&gt;
&lt;p&gt;We are convinced that &lt;em&gt;&lt;strong&gt;the close collaboration between experimentalists and theoreticians in neuroscience is essential to develop mechanistic as well as quantitative understandings of how the brain performs its functions&lt;/strong&gt;&lt;/em&gt;. This is in fact a primary motivating force in establishing this center. However, for such collaborations to be effective, experimentalists must be well aware of the approaches and challenges in modeling while theoreticians must be well acquainted with the experimental techniques, their power and the challenges they present. CONECT has also the ambition to contribute to the training of a new generation of neuroscientists who will have all these qualities.&lt;/p&gt;
&lt;p&gt;This approach is therefore complementary but distinct in its purpose from neuroinformatics (creation of tools for analyzing neuroscientific data) or artificial intelligence (creation of algorithms inspired by the functioning of the brain). The field of computational neuroscience is still young but its community is now structured in an autonomous community with strong interaction with the other branches of neuroscience. It is this autonomy that we want to foster at INT.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Actors of CONECT</title>
      <link>https://conect-int.github.io/post/actors-conect/</link>
      <pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/post/actors-conect/</guid>
      <description>&lt;p&gt;Within the INT, many components of CONECT already exist, either carried by researchers in computational neurosciences or as themes strongly anchored in this field. A survey of the current situation reveals the existence of projects at different scales.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://conect-int.github.io/contact&#34;&gt;Contact&lt;/a&gt; us to be added!&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;from the cellular to the network level
&lt;ul&gt;
&lt;li&gt;deciphering the biophysical principles underlying robustness of neuronal activity using quantitative genotype-to-phenotype mapping strategies and realistic neuronal model databases (&lt;strong&gt;Jean-Marc Goaillard&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;dynamics and function of small and large-scale neural networks: &lt;strong&gt;&lt;a href=&#34;https://conect-int.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent Perrinet&lt;/a&gt;&lt;/strong&gt; with &lt;a href=&#34;../../author/frederic-y-chavane&#34;&gt;Frédéric Chavane&lt;/a&gt;, &lt;strong&gt;&lt;a href=&#34;https://conect-int.github.io/authors/matthieu-gilson/&#34;&gt;Matthieu Gilson&lt;/a&gt;)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;from networks to mesoscopic levels :
&lt;ul&gt;
&lt;li&gt;Bayesian inference and predictive process models (&lt;strong&gt;&lt;a href=&#34;../../author/anna-montagnini&#34;&gt;Anna Montagnini&lt;/a&gt;&lt;/strong&gt;, &lt;a href=&#34;../../author/emmanuel-dauce&#34;&gt;Emmanuel Daucé&lt;/a&gt; and &lt;a href=&#34;https://conect-int.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent Perrinet&lt;/a&gt;), reinforcement learning, action selection, decision &lt;a href=&#34;../../author/andrea-brovelli&#34;&gt;Andrea Brovelli&lt;/a&gt; and &lt;a href=&#34;../../author/emmanuel-dauce&#34;&gt;Emmanuel Daucé&lt;/a&gt;), link with attentional mechanisms (Guilhem Ibos)&lt;/li&gt;
&lt;li&gt;information theory and functional connectivity for the analysis of cognitive brain networks (&lt;strong&gt;&lt;a href=&#34;../../author/andrea-brovelli&#34;&gt;Andrea Brovelli&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href=&#34;https://conect-int.github.io/authors/matthieu-gilson/&#34;&gt;Matthieu Gilson&lt;/a&gt;)&lt;/strong&gt; and &lt;a href=&#34;../../author/bruno-giordano&#34;&gt;Bruno Giordano&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;deep learning for data processing (&lt;strong&gt;&lt;a href=&#34;../../author/bruno-giordano&#34;&gt;Bruno Giordano&lt;/a&gt;&lt;/strong&gt;), deep learning + neuroimaging (&lt;em&gt;in voice perception&lt;/em&gt;) (Charly Lamothe) computational neuroscience and data processing in neuroinformatics (Sylvain Takerkart, NIT platform)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;at brain level
&lt;ul&gt;
&lt;li&gt;brain anatomy, particularly as applied to the formation of cortical folding (Julien Lefèvre with Guillaume Auzias, Sylvain Takerkart and &lt;strong&gt;&lt;a href=&#34;../../author/olivier-coulon&#34;&gt;Olivier Coulon&lt;/a&gt;&lt;/strong&gt;),&lt;/li&gt;
&lt;li&gt;the development of prognostic models of the evolution of certain pathologies (Lionel Velly, &lt;strong&gt;Sylvain Takerkart&lt;/strong&gt;),&lt;/li&gt;
&lt;li&gt;develop the collaboration of theoretical neurosciences with neuroinformatics, notably with the &lt;a href=&#34;http://www.int.univ-amu.fr/spip.php?page=plateform&amp;amp;equipe=CRISE&amp;amp;lang=fr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NIT&lt;/a&gt; (&lt;strong&gt;Sylvain Takerkart&lt;/strong&gt;, Guillaume Auzias)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A structuring of these different components through a center (independent of existing and future teams) would be a major asset to reach a new stage in the creation of INT³.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Objectives of CONECT</title>
      <link>https://conect-int.github.io/post/objectives-conect/</link>
      <pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/post/objectives-conect/</guid>
      <description>&lt;p&gt;The Computational Neuroscience Center (CONECT) is an incubator within the INT to promote theoretical and computational neuroscience.&lt;/p&gt;
&lt;p&gt;It ambitions to contribute to the training of a new generation of neuroscientists, following the revolution experienced by neuroscience over the past decades: tremendous technological advances across several disciplines have dramatically expanded the frontiers of experimentally accessible neuro-scientific facts. CONECT is thus concerned with new analysis tools and models that can account for large and complex datasets, in parallel with the NeuroTech Center that focuses on experimental devices.&lt;/p&gt;
&lt;p&gt;CONECT aims to build an inter-disciplinary community within the INT to foster interactions between computational neuroscientists and with experimentalists. The tools include scientific animation (journal clubs, seminars) and practical sessions to leanr and master new tools. This will participate in structuring the teaching and research environment around computational neuroscience around AMU beyond INT alone. The plan is to involve not only local research partners of INT like NeuroMarseille and the Laennec Institute, but also engineer schools (PolyTech, Centrale Marseille) and applied mathematics masters.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>2023-06-20: CONECT at the CENTURI summer school</title>
      <link>https://conect-int.github.io/talk/2023-06-20-conect-at-the-centuri-summer-school/</link>
      <pubDate>Tue, 20 Jun 2023 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2023-06-20-conect-at-the-centuri-summer-school/</guid>
      <description>&lt;h1 id=&#34;title-neural-computation-through-population-dynamics&#34;&gt;Title: Neural computation through population dynamics&lt;/h1&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Program in construction - you can already check the program of the &lt;a href=&#34;https://centuri-livingsystems.org/centuri-summer-school-2023/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;summer school&lt;/a&gt; (June 20 - July 01, 2023)!
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;question&#34;&gt;Question&lt;/h2&gt;
&lt;p&gt;Detecting precise spiking motifs in neurobiological data&lt;/p&gt;
&lt;h2 id=&#34;preliminary-program&#34;&gt;Preliminary program&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://centuri-livingsystems.org/wp-content/uploads/2018/02/SUMMER-SCHOOL-program-2023.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Detailed program&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Monday, June 19 – Room 4 at CIELL (Hexagone building – 1st floor)
&lt;ul&gt;
&lt;li&gt;14 – 16h : introduction par Rosa and Pierre&lt;/li&gt;
&lt;li&gt;16h-17h : group project presentation (in Hexagone auditorium)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tuesday, June 20
&lt;ul&gt;
&lt;li&gt;13h-14h15: group lunch at CROUS (booking in the small room)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tuesday, June 20 to Thursday, June 29
&lt;ul&gt;
&lt;li&gt;Afternoon 14:30 - 17:00: group projects in Room 4 at CIELL&lt;/li&gt;
&lt;li&gt;Room 4 at CIELL (Hexagone building- 1st floor)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Wednesday, June 28 and Thursday, June 29
&lt;ul&gt;
&lt;li&gt;Room 4 at CIELL (Hexagone building- 1st floor)&lt;/li&gt;
&lt;li&gt;All day: Group projects in Institutes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Friday, June 30 – HEXAGONE AUDITORIUM
&lt;ul&gt;
&lt;li&gt;09h30-12h: presentation of group projects&lt;/li&gt;
&lt;li&gt;12h-13h30 : group lunch – buffet in the HEXAGONE Hall&lt;/li&gt;
&lt;li&gt;13h30: end of the event&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;challenge&#34;&gt;Challenge&lt;/h2&gt;
&lt;p&gt;At any given instant, hundreds of billions of cells in our brains are lighting up in a complicated yet highly coordinated manner to give rise to our thoughts, percepts, and movements. A single neuron may be connected to thousands of other cells, sending out and receiving information through electrical impulses called spikes. From an engineering perspective, these spikes form a signal that may be viewed as a series of ones and zeros rapidly unfolding in time. Altogether, these signals reflect the ongoing computations taking place inside the nervous system, and as such, constitute a window into the brain’s inner workings. Recent advances in recording techniques have allowed experimenters to collect data from hundreds to thousands of neurons simultaneously while animals perform simple tasks. Dealing with such high-dimensional data poses important technical challenges that require elaborate methods for data mining and analysis. In this project, students will deal with datasets of increasing complexity and develop a set of analyses to extract meaningful information from the data.&lt;/p&gt;
&lt;h2 id=&#34;type-of-data&#34;&gt;Type of data&lt;/h2&gt;
&lt;p&gt;Data that will be shared by the teaching staff, under the BIDS standard data organization which is currently being extended to electrophysiology data by the members of the INT and the CONECT team. The data we will use consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;publicly available recordings from a reaching task&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;publicly available recordings from the dorsomedial frontal cortex of NHPs performing a time-interval reproduction task (&lt;a href=&#34;https://github.com/jazlab/Meirhaeghe2021&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/jazlab/Meirhaeghe2021&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;p&gt;Data visualisation, neural decoding, principal component analysis, kinematic and geometric analyses of neural trajectories in high-dimensional space, hypothesis-testing, null distributions and statistics&lt;/p&gt;
&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/CONECT-INT/2023_CENTURI-SummerSchool&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/CONECT-INT/2023_CENTURI-SummerSchool&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/SpikeAI/2022-11_brainhack_DetecSpikMotifs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/SpikeAI/2022-11_brainhack_DetecSpikMotifs&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2023-06-12: CONECT Workshop on Learning</title>
      <link>https://conect-int.github.io/talk/2023-06-12-conect-workshop-on-learning/</link>
      <pubDate>Mon, 12 Jun 2023 09:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2023-06-12-conect-workshop-on-learning/</guid>
      <description>&lt;h1 id=&#34;conect-workshop-active-learning-in-brains-and-machines&#34;&gt;CONECT Workshop &lt;em&gt;Active learning in brains and machines&lt;/em&gt;&lt;/h1&gt;
&lt;p&gt;We organized a one-day workshop on Monday, June 12th, at the Institut de Neurosciences de la Timone (INT), in the Gastaut room (9h-17h), campus Timone. The aim of CONECT one-day workshops was to gather computational neuroscientists and experimentalists around an open question in the field, with plenty of room for interaction and discussion.&lt;/p&gt;
&lt;p&gt;When? &lt;em&gt;12th of June 2023&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Where? &lt;a href=&#34;https://goo.gl/maps/MLpmsN9cd2N1Uv1L7&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Campus Timone (room Gastaut), Aix-Marseille Université&lt;/em&gt;, 27 Boulevard Jean Moulin, 13005 Marseille&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Organizers: Simon Nougaret, Emmanuel Daucé, Laurent Perrinet (mobile: 0619478120), Matthieu Gilson&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;attendees&#34; srcset=&#34;
               /talk/2023-06-12-conect-workshop-on-learning/IMG_1617_hu55ebe531ef629f2f9bbb055848de5bda_1416425_905e1d9d1d818029cf8732850e05ba9b.webp 400w,
               /talk/2023-06-12-conect-workshop-on-learning/IMG_1617_hu55ebe531ef629f2f9bbb055848de5bda_1416425_7d552a93f2d9086f7a07f05ed8a2a7af.webp 760w,
               /talk/2023-06-12-conect-workshop-on-learning/IMG_1617_hu55ebe531ef629f2f9bbb055848de5bda_1416425_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://conect-int.github.io/talk/2023-06-12-conect-workshop-on-learning/IMG_1617_hu55ebe531ef629f2f9bbb055848de5bda_1416425_905e1d9d1d818029cf8732850e05ba9b.webp&#34;
               width=&#34;570&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;topics&#34;&gt;Topics&lt;/h2&gt;
&lt;p&gt;In biology, a major trait of neural systems is the capability to &lt;em&gt;learn&lt;/em&gt;, that is, to adapt its behavior to the environment it interacts with. Recent advances in machine learning and deep learning have, in parallel, contributed to formulate learning in terms of optimizing performance under task-specific domains.&lt;/p&gt;
&lt;p&gt;While each field inspires the other, there is still a gap in our understanding of how learning in machines may compare or even relate to learning in biology. The goal of this workshop is to allow people from both computational and experimental sides to understand current research achievements and challenges about &lt;em&gt;active learning in brains and machines&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&#34;program&#34;&gt;PROGRAM&lt;/h3&gt;
&lt;p&gt;9:00 : Welcome &amp;amp; Introduction&lt;/p&gt;
&lt;h4 id=&#34;session-1--encoding-of-neuronal-representations-chair-emmanuel-daucé&#34;&gt;Session 1 : Encoding of neuronal representations (chair: Emmanuel Daucé)&lt;/h4&gt;
&lt;p&gt;9:15 : &lt;strong&gt;&lt;strong&gt;Alexandre Pitti&lt;/strong&gt;&lt;/strong&gt; (ETIS, CY-U, Cergy Pontoise): &amp;ldquo;Neuro-inspired mechanisms for sensorimotor and syntactic learning in language&amp;rdquo;&lt;/p&gt;
&lt;p&gt;9:55 : &lt;strong&gt;Laurie Mifsud &amp;amp; Matthieu Gilson&lt;/strong&gt; (INT, Marseille) &amp;ldquo;Statistical learning in bio-inspired neuronal network&amp;rdquo;&lt;/p&gt;
&lt;p&gt;10:15 : &lt;strong&gt;Antoine Grimaldi&lt;/strong&gt; (INT, Marseille) &amp;ldquo;Learning in networks of spiking neurons with heterogeneous delays&amp;rdquo;&lt;/p&gt;
&lt;p&gt;10:35 : coffee break&lt;/p&gt;
&lt;h4 id=&#34;session-2--learning-action-selection-chair-matthieu-gilson&#34;&gt;Session 2 : Learning action selection (chair: Matthieu Gilson)&lt;/h4&gt;
&lt;p&gt;11:00 : &lt;strong&gt;&lt;strong&gt;Jorge Ramirez Ruiz&lt;/strong&gt;&lt;/strong&gt; (Univ Pompeu Fabra, Barcelona) &amp;ldquo;Path occcupancy maximization principle&amp;rdquo;&lt;/p&gt;
&lt;p&gt;11:40 : &lt;strong&gt;Nicolas Meirhaeghe&lt;/strong&gt; (INT, Marseille) : &amp;ldquo;Bayesian Computation through Cortical Latent Dynamics&amp;rdquo;&lt;/p&gt;
&lt;p&gt;12:00 : &lt;strong&gt;Emmanuel Daucé &amp;amp; Hamza Oueld&lt;/strong&gt; (INT, Marseille) : &amp;ldquo;Principles of model-driven active sampling in the brain&amp;rdquo;&lt;/p&gt;
&lt;p&gt;12:30 : Meal&lt;/p&gt;
&lt;h4 id=&#34;session-3--neuronal-basis-of-vocal-representation-chair-laurent-perrinet&#34;&gt;Session 3 : Neuronal basis of vocal representation (chair: Laurent Perrinet)&lt;/h4&gt;
&lt;p&gt;14:00 : &lt;strong&gt;&lt;strong&gt;Thomas Schatz&lt;/strong&gt;&lt;/strong&gt; (LIS, Marseille): &amp;ldquo;Perceptual development, unsupervised representation learning and auditory neuroscience&amp;rdquo;&lt;/p&gt;
&lt;p&gt;14:40 : &lt;strong&gt;Charly Lamothe&lt;/strong&gt; (LIS/INT, Marseille) &amp;amp; &lt;strong&gt;Etienne Thoret&lt;/strong&gt; (PRISM/LIS/ILCB, Marseille): &amp;ldquo;Decoding voice identity from brain activity&amp;rdquo;&lt;/p&gt;
&lt;p&gt;15:00 : coffee break&lt;/p&gt;
&lt;h4 id=&#34;session-4--distribution-and-integration-of-brain-functions-chair-simon-nougaret&#34;&gt;Session 4 : Distribution and integration of brain functions (chair: Simon Nougaret)&lt;/h4&gt;
&lt;p&gt;15:30 : &lt;strong&gt;&lt;strong&gt;Jean-Rémi King&lt;/strong&gt;&lt;/strong&gt; (Meta / CNRS): &amp;ldquo;Language in the brain and algorithms&amp;rdquo;&lt;/p&gt;
&lt;p&gt;16:10 : &lt;strong&gt;Etienne Combrisson &amp;amp; Andrea Brovelli&lt;/strong&gt; (INT, Marseille) : &amp;ldquo;Cortico-cortical interactions for goal-directed causal learning&amp;rdquo;&lt;/p&gt;
&lt;p&gt;16:30 : Round table&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;attendees&#34; srcset=&#34;
               /talk/2023-06-12-conect-workshop-on-learning/IMG_7807_hua238fd24969325e44a2e5a20c16ddb0f_1676835_4213d5016f5c6256ba9380ce4d3e75b3.webp 400w,
               /talk/2023-06-12-conect-workshop-on-learning/IMG_7807_hua238fd24969325e44a2e5a20c16ddb0f_1676835_c1ac7a60351ca73a881e363dbcf38d44.webp 760w,
               /talk/2023-06-12-conect-workshop-on-learning/IMG_7807_hua238fd24969325e44a2e5a20c16ddb0f_1676835_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://conect-int.github.io/talk/2023-06-12-conect-workshop-on-learning/IMG_7807_hua238fd24969325e44a2e5a20c16ddb0f_1676835_4213d5016f5c6256ba9380ce4d3e75b3.webp&#34;
               width=&#34;760&#34;
               height=&#34;570&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstracts&#34;&gt;Abstracts&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Andrea Brovelli: &amp;ldquo;Cortico-cortical interactions for goal-directed learning&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;During my presentation, I will provide a concise overview of two recent studies that explore the significance of cortico-cortical interactions in goal-directed learning and the processing of outcome-related learning computations, specifically prediction errors. In the first study, we examined the interaction between human prefrontal and insular regions during reward and punishment learning. Using intracranial EEG recordings to measure high-gamma activity (HGA) and leveraging advancements in information theory, we discovered a functional distinction in inter-areal interactions between reward and punishment learning. A reward subsystem with redundant interactions was observed between the orbitofrontal and ventromedial prefrontal cortices, where the ventromedial prefrontal cortex played a Granger-causality driving role. Additionally, we identified a punishment subsystem with redundant interactions between the insular and dorsolateral cortices, with the insula acting as the primary driver. Furthermore, we found that the encoding of both reward and punishment prediction errors was mediated by synergistic interactions between these two subsystems. In the second study, we investigated the spatio-temporal characteristics of cortico-cortical interactions that support learning-related variables, such as reward-related signals (Bayesian surprise). Our results revealed the involvement of a distributed network comprising the visual, lateral prefrontal, and orbitofrontal cortex. Preliminary findings also indicated the presence of higher-order synergistic interactions that emerge from the combined activation of these networks.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Emmanuel Daucé &amp;amp; Hamza Oueld : &amp;ldquo;Principles of model-driven active sampling in the brain&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Understanding our environment requires not only passively observing sensory samples, but also acting to seek out useful relationships between our actions and their possible outcomes. Inspired by the concept of &amp;ldquo;visual salience&amp;rdquo;, we provide a way to interpret action selection as making an &amp;ldquo;ideal experiment&amp;rdquo;, in a behavioral task where participants estimate the causal influence of a player on the outcome of a volleyball game. We show that the balance between the accuracy and the diversity objectives can lead to specific action selection biases, reflected both in the model and in the data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Antoine Grimaldi: &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-bc/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Learning in networks of spiking neurons with heterogeneous delays&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;The response of a biological neuron depends on the precise timing of afferent spikes. This temporal aspect of the neural code is essential to understand information processing in neurobiology and applies particularly well to the output of neuromorphic hardware such as event-based cameras. However, most artificial neural models do not take advantage of this important temporal dimension of the neural code. Inspired by this neuroscientific observation, we develop a model for the efficient detection of temporal spiking motifs based on a layer of spiking neurons with heterogeneous synaptic delays. The model uses the property that the diversity of synaptic delays on the dendritic tree allows for the synchronization of specific arrangements of synaptic inputs as they reach the basal dendritic tree. We show that this can be formalized as a time-invariant logistic regression that can be trained on labeled data. We demonstrate its application to synthetic naturalistic videos transformed into event streams similar to the output of the retina or to event-based cameras and for which we will characterize the accuracy of the model in detecting visual motion. In particular, we quantify how the accuracy can vary as a function of the overall computational load showing it is still efficient at very low workloads. This end-to-end, event-driven computational building block could improve the performance of future spiking neural network (SNN) algorithms and in particular their implementation in neuromorphic chips.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Charly Lamothe &amp;amp; Etienne Thoret: &amp;ldquo;Decoding voice identity from brain activity&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Voice information processing in the brain involves specialized areas called temporal voice areas (TVAs), which respond more strongly to vocalizations from the same species. However, how these areas represent voice information, specifically speaker identity, is not well understood. To investigate this, we used a deep neural network (DNN) to create a compact representation of voice stimuli called the voice latent space (VLS). We then examined the relationship between the VLS and brain activity using various analyses. We discovered that the VLS correlates with cerebral activity measured by fMRI when exposed to thousands of voice stimuli from numerous speakers. The VLS also better captures the representation of speaker identity in the TVAs compared to the primary auditory cortex (A1). Additionally, the VLS enables reconstructions of voice stimuli in the TVAs that maintain important aspects of speaker identity, as confirmed by both machine classifiers and human listeners. These findings suggest that the DNN-derived VLS provides high-level representations of voice identity information in the TVAs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Jean-Rémi King: &amp;ldquo;Language in the brain and algorithms.&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Deep learning has recently made remarkable progress in natural language processing. Yet, the resulting algorithms fall short of the efficiency of the human brain. To bridge this gap, we here explore the similarities and differences between these two systems using large-scale datasets of magneto/electro-encephalography (M/EEG), functional Magnetic Resonance Imaging (fMRI), and intracranial recordings. After investigating where and when deep language algorithms map onto the brain, we show that enhancing these algorithms with long-range forecasts makes them more similar to the brain. Our results further reveal that, unlike current deep language models, the human brain is tuned to generate a hierarchy of long-range predictions, whereby the fronto-parietal cortices forecast more abstract and more distant representations than the temporal cortices. Overall, our studies show how the interface between AI and neuroscience clarifies the computational bases of natural language processing.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Nicolas Meirhaerghe: &amp;ldquo;Neural correlate of prior expectations in timing behavior&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;A central function of the brain is the capacity to anticipate the timing of future events based on past experience. Picture, for instance, a naive baseball player attempting to intercept an incoming ball. After a few failed trials, the player becomes increasingly close to striking the ball, and ultimately hits a home run. How does information about the past few throws help guide the timing of the player’s action? In this talk, I will present behavioral and electrophysiological data from non-human primates aimed at understanding how temporal expectations are represented in the brain. Specifically, I will address the following two questions: (1) how prior knowledge about the timing of a future event is encoded at the level of single neurons, and induces systematic biases in behavior; (2) what type of neural and behavioral changes occur when temporal expectations change in a dynamic environment.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Laurie Mifsud &amp;amp; Matthieu Gilson: &amp;ldquo;Statistical learning in bio-inspired neuronal network&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;In biological neuronal networks, information representation and processing like learning by synaptic plasticity rules are not only related to first-order statistics (i.e. mean firing rate) but also second and higher-order statistics in spike trains. This palces the focus on the temporal structure of distributed spiking activity, at several timescales. In parallel, recent models in machine learning like deep temporal convolutional networks have switched from inputs like static images to time series. In both cases, the goal is to extract spatio-temporal patterns of activity and it can be framed in the context of statistical learning. We will start from experimental evidence about spiking activity during a cognitive task, then present recent work combining covariance-based learning and reservoir computing to classify time series. The results highlight the important role for the recurrent connectivity in transforming information representations in biologically inspired architectures. Finally, we will see how to use this supervised learning framework to tune a recurrently connected population to experimental spiking data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Alex Pitti : &amp;ldquo;Neuro-inspired mechanisms for sensorimotor and syntactic learning in language&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;I propose that two neural mechanisms are at work for language acquisition. On the one hand, predictive coding and on the other hand, serial order coding. Predictive coding helps connect causes to effects in sensorimotor coordination during voice learning. While serial order codes allow pattern recognition in sentences to extract syntactic rules and hierarchy. The coupling between two neural architectures based on these two mechanisms, resp. the cortico-basal system and the fronto-striatum system can be used for the acquisition and categorization of sound primitives (syllables) and sequences (words). As a surprising extension of this idea, we have found that serial codes produce as well efficient coding and can reach Shannon&amp;rsquo;s limit in terms of information capacity. Langage is a compressive representation of information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Jorge Ramirez Ruiz: &amp;ldquo;A maximum occupancy principle for brains and behavior&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;The usual approach to analyze naturalistic behavior is to define its function as some form of reward or utility maximization. However, inferring the reward function for natural agents or designing one for artificial ones is problematic due to the unobservability of internal states and to the appearance of unintended behavior, respectively. Here, we abandon the idea of reward maximization and propose a principle of behavior based on the intrinsic motivation to maximize the occupancy of future action and state paths. We reconceptualize ‘reward’ as means to occupy paths, instead of the goals. We show that goal-directed behavior emerges from this principle by applying it to various discrete and continuous state tasks. In particular, we can apply this principle to a network of recurrently connected neurons, and we show that it is possible to produce highly variable activity while avoiding the saturation of the units. This work provides a proof of concept that goal-directedness is possible in the complete absence of external reward maximization.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Thomas Schatz: &amp;ldquo;Perceptual development, unsupervised representation learning and auditory neuroscience&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;I will draw from ongoing research projects at the interface between developmental psychology, machine learning, and computational neuroscience, to illustrate how, in my view, perspectives from each of these fields may contribute to the others. More specifically, I will discuss how considerations from developmental psychology and computational neuroscience can inform the design of novel algorithms for the unsupervised learning of speech representations and how the study of these algorithms may, in turn, lead to a deeper understanding of dynamic signal processing in the human brain and of perceptual development in infancy.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>2023-03-28: CONECT thematic day on Spiking Neural Networks</title>
      <link>https://conect-int.github.io/talk/2023-03-28-conect-thematic-day-on-spiking-neural-networks/</link>
      <pubDate>Tue, 28 Mar 2023 10:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2023-03-28-conect-thematic-day-on-spiking-neural-networks/</guid>
      <description>&lt;p&gt;This meet-up was focused on &lt;strong&gt;discussing recent developments in Spiking Neural Networks&lt;/strong&gt;, with plenty of time for discussion.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We met at INT, Laurent Vinay meeting room.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;program&#34;&gt;program&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;10:00&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Laurent Perrinet&lt;/li&gt;
&lt;li&gt;Title: &lt;strong&gt;A short intro on &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Precise Spiking Motifs in Neurobiological and Neuromorphic Data&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&#34;https://conect-int.github.io/slides/2023-03-28-conect-seminar-day-on-snns/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://conect-int.github.io/slides/2023-03-28-conect-seminar-day-on-snns/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;10:30&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://homepages.cwi.nl/~sbohte/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sander Bohte&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Title: &lt;strong&gt;Scaling Up Spiking Neural Networks with Online Learning in Gated Spiking Neurons&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;11:30&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Antoine Grimaldi, PhD student (INT)&lt;/li&gt;
&lt;li&gt;Title: &lt;strong&gt;&lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-bc/grimaldi-22-bc.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learning heterogeneous delays in a layer of spiking neurons for fast motion detection&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;The response of a biological neuron depends on the precise timing of afferent spikes. This temporal aspect of the neuronal code is essential in understanding information processing in neurobiology and applies particularly well to the output of neuromorphic hardware such as event-based cameras. However, most artificial neuronal models do not take advantage of this minute temporal dimension. Inspired by this neuroscientific observation, we develop a model for the efficient detection of temporal spiking motifs based on a layer of spiking neurons with heterogeneous delays which we apply to the computer vision task of motion detection. Indeed, the variety of synaptic delays on the dendritic tree allows synchronizing synaptic inputs as they reach the basal dendritic tree. We show this can be formalized as a time-invariant logistic regression which can be trained using labeled data. We apply this model to solve the specific computer vision problem of motion detection, and demonstrate its application to synthetic naturalistic videos transformed into event streams similar to the output of event-based cameras. In particular, we quantify how the accuracy of the model can vary with the total computational load. This end-to-end event-driven computational brick could help improve the performance of future spiking neural network algorithms and their prospective use in neuromorphic chips.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;12:00 Lunch time (at INT R+4, will be provided only for people registered below)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;14:00&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pr. Benoît Miramond (LEAT, Université Côte d&amp;rsquo;Azur)&lt;/li&gt;
&lt;li&gt;Title: &lt;strong&gt;Estimating Energy Efficiency of Spiking Neural Networks on neuromorphic hardware&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Spiking Neural Networks are a type of neural networks where neurons communicate using only spikes. They are often presented as a low-power alternative to classical neural networks, but few works have proven these claims to be true. In this work, we present a metric to estimate the energy consumption of SNNs independently of a specific hardware. We then apply this metric on SNNs processing three different data types (static, dynamic and event-based) representative of real-world applications. As a result, all of our SNNs are 6 to 8 times more efficient than their FNN counterparts.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;15:00 break&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;15:30&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dr. Andrea Castagnetti (LEAT, Université Côte d&amp;rsquo;Azur)&lt;/li&gt;
&lt;li&gt;Title: &lt;a href=&#34;https://www.frontiersin.org/articles/10.3389/fnins.2023.1154241/full&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Trainable quantization for Speedy Spiking Neural Networks&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Spiking neural networks are considered as the third generation of Artificial Neural Networks. SNNs perform computation using neurons and synapses that communicate using binary and asynchronous signals known as spikes. They have attracted significant research interest over the last years since their computing paradigm allows theoretically sparse and low-power operations. This hypothetical gain, used from the beginning of the neuromorphic research, was however limited by three main factors: the absence of an efficient learning rule competing with the one of classical deep learning, the lack of mature learning framework, and an important data processing latency finally generating energy overhead. While the first two limitations have recently been addressed in the literature, the major problem of latency is not solved yet. Indeed, information is not exchanged instantaneously between spiking neurons but gradually builds up over time as spikes are generated and propagated through the network. This presentation focuses on quantization error, one of the main consequence of the SNN discrete representation of information. We propose an in-depth characterization of SNN quantization noise. We then propose a end-to-end direct learning approach based on a new trainable spiking neural model.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;16:00&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Yann Cherdo, PhD student (LEAT, Université Côte d&amp;rsquo;Azur - Renault)&lt;/li&gt;
&lt;li&gt;Title: &lt;strong&gt;HTM and SNN for a bio inspired time series forecasting&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;In the recent years, Spiking Neural Networks have gain much attention from the research community. They can now be trained using the powerful gradient descent and have drifted from the neuroscience to the Machine Learning community. An abundant literature shows that they can perform well on classical Artificial Intelligence tasks such as image or signal classification while consuming less energy than state-of-the-art models like Convolutional Neural Networks. Yet, there is very little work about their performance on unsupervised anomaly detection and time-series prediction. Indeed, the processing of such temporal data requires different encoding and decoding mechanisms and rises questions about their capacity to model a dynamical signal with long term temporal dependencies. In this presentation, we propose a comparison between Sparse Recurrent Spiking Neural Network and Hierarchical Temporal Memories (HTM). We show that both models perform well on temporal tasks and open a door for further studies of embedded applications for Spiking Neural Networks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;17:00 outro&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>CONECT thematic day on Spiking Neural Networks</title>
      <link>https://conect-int.github.io/slides/2023-03-28-conect-seminar-day-on-snns/</link>
      <pubDate>Tue, 28 Mar 2023 10:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/slides/2023-03-28-conect-seminar-day-on-snns/</guid>
      <description>
&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/open-book.jpg&#34;
  &gt;

&lt;h1 id=&#34;spiking-neural-networks&#34;&gt;Spiking Neural Networks&lt;/h1&gt;
&lt;h2 id=&#34;conect-thematic-day&#34;&gt;CONECT thematic day&lt;/h2&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;li&gt;Hi, I am LP and in the name of CONECT, we look forward to discuss on SNNs&lt;/li&gt;
&lt;li&gt;as part of the CONECT&amp;hellip;&lt;/li&gt;
&lt;li&gt;In this short presentation, we will present the challenges that we want to tackle and which we named&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;img data-src=&#34;https://conect-int.github.io/slides/conect/CONECT-logo.png&#34; height=&#34;200&#34; /&gt;
&lt;p&gt;&lt;a href=&#34;https://conect-int.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CONECT: Computational Neuroscience Center @ INT&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;-so, what is CONECT?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CONECT is Computational Neuroscience Center @ INT, bringing together a core of theoretician&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;aims at making bridges in neuroscience&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;and across the community&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;challenge-visual-latencies&#34;&gt;Challenge: Visual latencies&lt;/h2&gt;
&lt;img data-src=&#34;https://github.com/SpikeAI/2022_polychronies-review/raw/main/figures/visual-latency-estimate.jpg&#34; height=&#34;420&#34; /&gt;
&lt;p&gt;&lt;a href=&#34;https://doi.org/10.1126/science.1058249&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Thorpe &amp;amp; Fabre-Thorpe, 2001&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In particular in our group, we are interested in dynamics of neural processing&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The visual system is very efficient in generating a decision from the retinal image to the different  stages of the visual pathways, here for a macaque monkey, a reaction of finger muscles in about 300 milliseconds.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the process of categorizing an object takes 10 layers&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;challenge-visual-latencies-1&#34;&gt;Challenge: Visual latencies&lt;/h2&gt;
&lt;img data-src=&#34;https://github.com/SpikeAI/2022_polychronies-review/raw/main/figures/visual-latency.jpg&#34; height=&#34;420&#34; /&gt;
&lt;p&gt;Review on &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Precise Spiking Motifs&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the latencies are of similar in the human brain but merely scaled due to the brain size&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;as a consequence, it is thought that this efficiency is achieved by spikes that is, brief all-or-none events which are passed in the very large network which forms the brain from assemblies of neurons to others.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;key-spiking-neural-networks&#34;&gt;Key: Spiking Neural Networks&lt;/h2&gt;
&lt;img data-src=&#34;https://github.com/SpikeAI/2022_polychronies-review/raw/main/figures/replicating_MainenSejnowski1995.png&#34; height=&#34;420&#34; /&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/SpikeAI/2022_polychronies-review/blob/main/src/Figure_2_MainenSejnowski1995.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mainen Sejnowski, 1995&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;reproduucibility&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;key-spiking-neural-networks-1&#34;&gt;Key: Spiking Neural Networks&lt;/h2&gt;
&lt;img data-src=&#34;https://github.com/SpikeAI/2022_polychronies-review/raw/main/figures/Diesmann_et_al_1999.png&#34; height=&#34;420&#34; /&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/SpikeAI/2022_polychronies-review/blob/main/src/Figure_3_Diesmann_et_al_1999.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Diesmann et al. 1999&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;This hypothesis is reviewed with respect to our knowledge of the neurobiology, for instance in the hippocampus of rodents. We also review&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;hypothesis-spiking-motifs&#34;&gt;Hypothesis: Spiking motifs&lt;/h2&gt;
&lt;img data-src=&#34;https://github.com/SpikeAI/2022_polychronies-review/raw/main/figures/haimerl2019.jpg&#34; height=&#34;420&#34; /&gt;
&lt;p&gt;Review on &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Precise Spiking Motifs&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This hypothesis is reviewed with respect to our knowledge of the neurobiology, for instance in the hippocampus of rodents. We also review&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;hypothesis-spiking-motifs-1&#34;&gt;Hypothesis: Spiking motifs&lt;/h2&gt;
&lt;img data-src=&#34;https://github.com/SpikeAI/2022_polychronies-review/raw/main/figures/Ikegaya2004zse0150424620001.jpeg&#34; height=&#34;420&#34; /&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;numerous and extensive work on mechanisms which may allow the neural system to learn to actually use that precise spiking motifs by attuning the delay between pairs of neurons.&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;hypothesis-spiking-motifs-2&#34;&gt;Hypothesis: Spiking motifs&lt;/h2&gt;
&lt;img data-src=&#34;https://github.com/SpikeAI/2022_polychronies-review/raw/main/figures/izhikevich.png&#34; height=&#34;420&#34; /&gt;
&lt;p&gt;Review on &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-polychronies/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Precise Spiking Motifs&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Izhikevich polychronization&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;yet the domain is vast, and there s lot to do in SNNs&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;todays-program&#34;&gt;Today&amp;rsquo;s program&amp;hellip;&lt;/h2&gt;
 &lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;&lt;img data-src=&#34;https://www.cwi.nl/intranet/faces/1152.jpg&#34; height=&#34;175&#34; /&gt;&lt;/th&gt;
    &lt;th&gt;&lt;img data-src=&#34;https://laurentperrinet.github.io/author/antoine-grimaldi/avatar_hu85406bb2d5f7db2dce1cab01b4e48063_27520_270x270_fill_q75_lanczos_center.jpg&#34; height=&#34;175&#34; /&gt;&lt;/th&gt;
    &lt;th&gt;&lt;img data-src=&#34;https://3ia.univ-cotedazur.eu/medias/photo/benoit-miramond_1621434732805-png?ID_FICHE=1087703&#34; height=&#34;175&#34; /&gt;&lt;/th&gt;
    &lt;th&gt;&lt;img data-src=&#34;https://phd-seminars-sam.inria.fr/files/2019/04/photo_Andrea_Castagnetti-235x300.jpg&#34; height=&#34;175&#34; /&gt;&lt;/th&gt;
    &lt;th&gt;&lt;img data-src=&#34;https://media.licdn.com/dms/image/C4D03AQG1wCHtwVhGYg/profile-displayphoto-shrink_400_400/0/1582485965416?e=1685577600&amp;v=beta&amp;t=oUiVlWlAQLG9rnz0nu0r-TdZ2LftDopThqB51nx4vQc&#34; height=&#34;175&#34; /&gt;&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Sander&lt;BR&gt;Bohte&lt;/td&gt;
    &lt;td&gt;Antoine&lt;BR&gt;Grimaldi&lt;/td&gt;
    &lt;td&gt;Benoit&lt;BR&gt;Miramond&lt;/td&gt;
    &lt;td&gt;Andrea&lt;BR&gt;Castagnetti&lt;/td&gt;
    &lt;td&gt;Yann&lt;BR&gt;Cherdo&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a href=&#34;https://conect-int.github.io/talk/2023-03-28-conect-thematic-day-on-spiking-neural-networks/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Program &amp;amp; more&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
</description>
    </item>
    
    <item>
      <title>2023-01-05 : CONECT seminar by Guillaume Dumas</title>
      <link>https://conect-int.github.io/talk/2023-01-05-conect-seminar-by-guillaume-dumas/</link>
      <pubDate>Thu, 05 Jan 2023 16:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2023-01-05-conect-seminar-by-guillaume-dumas/</guid>
      <description>&lt;p&gt;During this CONECT seminar, &lt;a href=&#34;https://www.extrospection.eu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Guillaume Dumas&lt;/a&gt; will present his recent work on &amp;ldquo;&lt;strong&gt;Multilevel Development of Cognitive Abilities in an Artificial Neural Network&lt;/strong&gt;&amp;rdquo;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Several neuronal mechanisms have been proposed to account for the formation of cognitive abilities through postnatal interactions with the physical and socio-cultural environment. Here, we introduce a three-level computational model of information processing and acquisition of cognitive abilities. We propose minimal architectural requirements to build these levels and how the parameters affect their performance and relationships. The first sensorimotor level handles local nonconscious processing, here during a visual classification task. The second level or cognitive level globally integrates the information from multiple local processors via long-ranged connections and synthesizes it in a global, but still nonconscious manner. The third and cognitively highest level handles the information globally and consciously. It is based on the Global Neuronal Workspace (GNW) theory and is referred to as conscious level. We use trace and delay conditioning tasks to, respectively, challenge the second and third levels. Results first highlight the necessity of epigenesis through selection and stabilization of synapses at both local and global scales to allow the network to solve the first two tasks. At the global scale, dopamine appears necessary to properly provide credit assignment despite the temporal delay between perception and reward. At the third level, the presence of interneurons becomes necessary to maintain a self-sustained representation within the GNW in the absence of sensory input. Finally, while balanced spontaneous intrinsic activity facilitates epigenesis at both local and global scales, the balanced excitatory-inhibitory ratio increases.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;More info: &lt;a href=&#34;https://www.pnas.org/doi/10.1073/pnas.2201304119&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.pnas.org/doi/10.1073/pnas.2201304119&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Keywords: computational biology, dynamical systems, medical machine learning (ML), neuroscience, AI ethics&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Guillaume Dumas is an Associate Professor of Computational Psychiatry in the Faculty of Medicine at the Université de Montréal, and the Principle Investigator of the Precision Psychiatry and Social Physiology laboratory at the CHU Sainte-Justine Research Center. He holds the IVADO professorship for “AI in Mental Health”, and the FRQS J1 in “AI and Digital Health”.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>2022-11-28: CONECT at the INT brainhack: Automatic detection of spiking motifs in neurobiological data</title>
      <link>https://conect-int.github.io/talk/2022-11-28-conect-at-the-int-brainhack-automatic-detection-of-spiking-motifs-in-neurobiological-data/</link>
      <pubDate>Mon, 28 Nov 2022 09:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2022-11-28-conect-at-the-int-brainhack-automatic-detection-of-spiking-motifs-in-neurobiological-data/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;TL;DR This project aims to develop a method for the automated detection of repeating spiking motifs, possibly noisy, in ongoing activity. Results are available on the shared repo: &lt;a href=&#34;https://github.com/SpikeAI/2022-11_brainhack_DetecSpikMotifs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/SpikeAI/2022-11_brainhack_DetecSpikMotifs&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://mattermost.brainhack.org/brainhack/channels/bhg22-marseille-detecspikmotifs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mattermost channel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;h3 id=&#34;leaders&#34;&gt;Leaders&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://matthieugilson.eu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Matthieu Gilson&lt;/a&gt; - &lt;a href=&#34;https://github.com/MatthieuGilson&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/MatthieuGilson&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://laurentperrinet.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Laurent Perrinet&lt;/a&gt; - &lt;a href=&#34;https://github.com/LaurentPerrinet&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/LaurentPerrinet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;collaborators&#34;&gt;Collaborators&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Hugo Ladret&lt;/li&gt;
&lt;li&gt;George Abitbol&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;brainhack-global-2022-event&#34;&gt;Brainhack Global 2022 Event&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://brainhack-marseille.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brainhack Marseille&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;supported by the &lt;a href=&#34;https://laurentperrinet.github.io/grant/polychronies/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Polychronies&lt;/a&gt; grant&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;project-description&#34;&gt;Project Description&lt;/h3&gt;
&lt;p&gt;The study of spatio-temporal correlated activity patterns is very active in several fields related to neuroscience, like machine learning in vision &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/29563572/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(Muller Nat Rev Neurosci 2018)&lt;/a&gt; and neuronal representations and processing &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/31110324/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(Shahidi Nat Neurosci 2019)&lt;/a&gt;. &lt;strong&gt;This project aims to develop a method for the automated detection of repeating spiking motifs, possibly noisy, in ongoing activity.&lt;/strong&gt; A diversity of formalizations and detection methods have been proposed and we will focus on several example measures for event/spike trains, to be compared on both synthetic and real data.&lt;/p&gt;
&lt;p&gt;An implementation could be based on autodifferentiable networks as implemented in Python libraries like pytorch. This framework allows for the tuning of parameters with specific architectures like convolutional layers that can capture various timescales in spike patterns (e.g. latencies) in an automated fashion. Another recent tool based on the estimation of firing probability for a range of latencies has been proposed &lt;a href=&#34;https://laurentperrinet.github.io/publication/grimaldi-22-bc/grimaldi-22-bc.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(Grimaldi ICIP 2022)&lt;/a&gt;. This will be compared with existing approaches like Elephant’s &lt;a href=&#34;https://elephant.readthedocs.io/en/latest/reference/spade.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SPADE&lt;/a&gt; or decoding techniques based on computed statistics computed on smoothed spike trains (adapted from time series processing, see &lt;a href=&#34;https://doi.org/10.1101/2021.04.30.441789&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(Lawrie, biorxiv&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;One part concerns the generation of realistic synthetic data producing spike trains  which include spiking motifs with specific latencies or comodulation of firing rate. The goal is to test how these different structures, which rely on specific assumptions about e.g. stationarity or independent firing probability across time, can be captured by different detection methods.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2022-11-24 : CONECT seminar by Bruno Cessac</title>
      <link>https://conect-int.github.io/talk/2022-11-24-conect-seminar-by-bruno-cessac/</link>
      <pubDate>Thu, 24 Nov 2022 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2022-11-24-conect-seminar-by-bruno-cessac/</guid>
      <description>&lt;p&gt;During this CONECT seminar, &lt;a href=&#34;https://team.inria.fr/biovision/bruno-cessac/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bruno Cessac&lt;/a&gt; did present his recent work on &amp;ldquo;&lt;strong&gt;Retinal processing: Insights from mathematical modelling&lt;/strong&gt;&amp;rdquo;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The retina is the entrance of the visual system. Although based on common biophysical principles, the dynamics of retinal neurons are quite different from their cortical counterparts, raising interesting problems for modellers. In this paper, I address some mathematically stated questions in this spirit, discussing, in particular: (1) How could lateral amacrine cell connectivity shape the spatio-temporal spike response of retinal ganglion cells? (2) How could spatio-temporal stimuli correlations and retinal network dynamics shape the spike train correlations at the output of the retina? These questions are addressed, first, introducing a mathematically tractable model of the layered retina, integrating amacrine cells’ lateral connectivity and piecewise linear rectification, allowing for computing the retinal ganglion cells receptive field together with the voltage and spike correlations of retinal ganglion cells resulting from the amacrine cells networks. Then, I review some recent results showing how the concept of spatio-temporal Gibbs distributions and linear response theory can be used to characterize the collective spike response to a spatio-temporal stimulus of a set of retinal ganglion cells, coupled via effective interactions corresponding to the amacrine cells network. On these bases, I briefly discuss several potential consequences of these results at the cortical level.
Keywords: retinal network; visual system; spatio-temporal spike correlations; linear response; non stationarity&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    My research was initially modeling and analysis of large sized dynamical systems arising in various fields such as physics, biology, sociology, computers networks. I have worked on subjects such as self-organized criticality, linear response in chaotic systems, social networks, communications networks. My main interest concerns neuronal networks dynamics. I have developed methods combining dynamical systems theory, statistical physics and ergodic theory allowing to classify dynamics arising in canonical neuronal networks models like integrate and fire models or firing rate models. I have applied these methods for the study of synaptic and intrinsic plasticity, dynamical learning, spike coding, spike train statistics analysis, mean-field dynamics. I am now involved in developing models for the visual system, especially the retina, as well as numerical methods and software for neuroscientists.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>2022-09-08 : CONECT seminar by Charlie Sexton</title>
      <link>https://conect-int.github.io/talk/2022-09-08-conect-seminar-by-charlie-sexton/</link>
      <pubDate>Thu, 08 Sep 2022 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2022-09-08-conect-seminar-by-charlie-sexton/</guid>
      <description>&lt;p&gt;During this CONECT seminar, &lt;a href=&#34;https://psychologicalsciences.unimelb.edu.au/research/msps-research-groups/timing/lab/people#&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Charlie Sexton&lt;/a&gt; will present his recent work on &amp;ldquo;&lt;strong&gt;Spike-timing dependent plasticity among multiple layers of motion-sensitive neurons: a feedforward mechanism for motion extrapolation&lt;/strong&gt;&amp;rdquo;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The ability of the brain to represent the external world in real-time is impacted by the fact that neural processing takes time. Because neural delays accumulate as information progresses through the visual system, representations encoded at each hierarchical level are based upon input that is progressively outdated with respect to the external world. This is particularly relevant to the task of localizing a moving object – because the object’s location changes with time, neural representations of its location potentially lag behind its true location. It has therefore been proposed that the visual system utilizes the predictive nature of motion to extrapolate moving objects along their trajectory. Burkitt and Hogendoorn (2021, &lt;a href=&#34;https://doi.org/10.1523/JNEUROSCI.2017-20.2021&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1523/JNEUROSCI.2017-20.2021&lt;/a&gt;) showed how spike-timing dependent plasticity (STDP) can achieve motion extrapolation in a two-layer, feedforward network of velocity-tuned neurons, by shifting the receptive-fields of second-layer neurons in the opposite direction to a moving stimulus. The current study extends this work by implementing two important changes to the network to bring it more into line with biology: we expanded the network to multiple layers to reflect the depth of the visual hierarchy, and we implemented more realistic synaptic time-courses. We examine the degree to which STDP can facilitate compensation of neural delays across six layers, and show that the multi-layer network achieves cumulative compensation comparable in magnitude to the delays incurred in visual processing. We also explore the effect of additional delays imposed on the network by the integration time of the membrane potential.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    More about Charlie: So far in my PhD I have looked at how spike-timing dependent plasticity (STDP) can shift feedforward connection strengths between levels of the visual hierarchy, such that higher levels encode moving objects further along their trajectory (as a mechanism for motion extrapolation). The project began with a paper by my supervisors, Hinze Hogendoorn and Tony Burkitt: &lt;a href=&#34;https://www.jneurosci.org/content/41/20/4428.abstract&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.jneurosci.org/content/41/20/4428.abstract&lt;/a&gt;. I have been working on extending this model network to have 6 layers to see the combined effect of plasticity at several visual areas. I will attach my abstract for my ECVP talk here.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>2022-06-20: CONECT at the CENTURI summer school</title>
      <link>https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/</link>
      <pubDate>Mon, 20 Jun 2022 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/</guid>
      <description>&lt;h1 id=&#34;title-neural-computation-through-population-dynamics&#34;&gt;Title: Neural computation through population dynamics&lt;/h1&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;The CENTURI &lt;a href=&#34;https://twitter.com/hashtag/SummerSchool?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#SummerSchool&lt;/a&gt; 2022 has been launched this morning ! Rosa Cossart has welcomed all the participants this morning.👾&lt;br&gt;&lt;br&gt;Excited to begin these two weeks of transfer of knowledge and deep thinking at &lt;a href=&#34;https://twitter.com/univamu?ref_src=twsrc%5Etfw&#34;&gt;@univamu&lt;/a&gt;&lt;br&gt;!👏&lt;br&gt;&lt;br&gt;For more info➡️&lt;a href=&#34;https://t.co/K2oyuQWsmb&#34;&gt;https://t.co/K2oyuQWsmb&lt;/a&gt; &lt;a href=&#34;https://t.co/bAldJeyssj&#34;&gt;pic.twitter.com/bAldJeyssj&lt;/a&gt;&lt;/p&gt;&amp;mdash; CENTURI - Turing Centre for Living Systems (@centuri_ls) &lt;a href=&#34;https://twitter.com/centuri_ls/status/1538893493828997123?ref_src=twsrc%5Etfw&#34;&gt;June 20, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The summer school is now over! You can check the program of the &lt;a href=&#34;https://centuri-livingsystems.org/centuri-summer-school-2022/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;summer school&lt;/a&gt; (June 20 - July 01, 2022)!
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;question&#34;&gt;Question&lt;/h2&gt;
&lt;p&gt;How does neural population dynamics relate to behaviorally-relevant computations?&lt;/p&gt;
&lt;h2 id=&#34;challenge&#34;&gt;Challenge&lt;/h2&gt;
&lt;p&gt;At any given instant, hundreds of billions of cells in our brains are lighting up in a complicated yet highly coordinated manner to give rise to our thoughts, percepts, and movements. A single neuron may be connected to thousands of other cells, sending out and receiving information through electrical impulses called spikes. From an engineering perspective, these spikes form a signal that may be viewed as a series of ones and zeros rapidly unfolding in time. Altogether, these signals reflect the ongoing computations taking place inside the nervous system, and as such, constitute a window into the brain’s inner workings. Recent advances in recording techniques have allowed experimenters to collect data from hundreds to thousands of neurons simultaneously while animals perform simple tasks. Dealing with such high-dimensional data poses important technical challenges that require elaborate methods for data mining and analysis. In this project, students will deal with datasets of increasing complexity and develop a set of analyses to extract meaningful information from the data.&lt;/p&gt;
&lt;h2 id=&#34;type-of-data&#34;&gt;Type of data&lt;/h2&gt;
&lt;p&gt;Data that will be shared by the teaching staff, under the BIDS standard data organization which is currently being extended to electrophysiology data by the members of the INT and the CONECT team. The data we will use consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;publicly available recordings from the dorsomedial frontal cortex of NHPs performing a time-interval reproduction task (&lt;a href=&#34;https://github.com/jazlab/Meirhaeghe2021&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/jazlab/Meirhaeghe2021&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;publicly available recordings from the motor cortex (M1/PMd) during an instructed reach-to-grasp task (&lt;a href=&#34;https://www.nature.com/articles/sdata201855&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.nature.com/articles/sdata201855&lt;/a&gt;, available at the following URL in BIDS: &lt;a href=&#34;https://gin.g-node.org/sprenger/multielectrode_grasp/src/bep_animalephys&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gin.g-node.org/sprenger/multielectrode_grasp/src/bep_animalephys&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.03.30.437692v5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.biorxiv.org/content/10.1101/2021.03.30.437692v5&lt;/a&gt; : V1, gratings-like, natural stimulations : extracellular electrophy recordings in cat V1&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;p&gt;Data visualisation, neural decoding, principal component analysis, kinematic and geometric analyses of neural trajectories in high-dimensional space, hypothesis-testing, null distributions and statistics&lt;/p&gt;
&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/CONECT-INT/2022_CENTURI-SummerSchool_private&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/CONECT-INT/2022_CENTURI-SummerSchool_private&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/CONECT-INT/2022_CENTURI-SummerSchool&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/CONECT-INT/2022_CENTURI-SummerSchool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Computational Neuroscience projet</title>
      <link>https://conect-int.github.io/slides/2022-06-20-conect-centuri-summer-school/</link>
      <pubDate>Mon, 20 Jun 2022 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/slides/2022-06-20-conect-centuri-summer-school/</guid>
      <description>
&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/open-book.jpg&#34;
  &gt;

&lt;h1 id=&#34;computational-neuroscience-projet&#34;&gt;Computational Neuroscience projet&lt;/h1&gt;
&lt;h2 id=&#34;centuri-summer-school&#34;&gt;CENTURI Summer school&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;li&gt;Hi, we are LP and NM and we look forward to start working with you on this project&lt;/li&gt;
&lt;li&gt;as part of the CENTURI summer school - and we would like to thank the organizers of the school&amp;hellip;&lt;/li&gt;
&lt;li&gt;In this short presentation, we will present the challenges that we want to tackle and which we named&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;who-are-we&#34;&gt;Who are we?&lt;/h2&gt;
 &lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;&lt;img data-src=&#34;https://conect-int.github.io/authors/nicolas-meirhaeghe/avatar.jpg&#34; height=&#34;200&#34; /&gt;&lt;/th&gt;
    &lt;th&gt;&lt;img data-src=&#34;https://conect-int.github.io/authors/laurent-u-perrinet/avatar.jpg&#34; height=&#34;200&#34; /&gt;&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Nicolas&lt;BR&gt;Meirhaeghe&lt;/td&gt;
    &lt;td&gt;Laurent&lt;BR&gt;Perrinet&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;challenge-brain-decoding&#34;&gt;Challenge: brain decoding&lt;/h2&gt;
&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/decoding.png&#34; height=&#34;420&#34; /&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;our brains light up billions of cells in a structured way,&lt;/li&gt;
&lt;li&gt;neural activity is in majority carried by action potentials, or &lt;em&gt;spikes&lt;/em&gt;,&lt;/li&gt;
&lt;li&gt;we wish to better understand this structure by using machine learning.&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;objectives&#34;&gt;Objectives&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Learn computational methods to interpret and interrogate neural data&lt;/li&gt;
&lt;li&gt;Learn to reduce the complexity of high-dimensional neural data&lt;/li&gt;
&lt;li&gt;Learn statistical approaches to perform hypothesis-testing on neural data&lt;/li&gt;
&lt;li&gt;Learn the principles of decoding analyses to relate neural data to behavioral data&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTES&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;datasets&#34;&gt;Datasets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Dataset 1: reaching task (Hatsopoulos et al., J. Neurophysiol., 2004)&lt;/li&gt;
&lt;li&gt;Dataset 2: grasping task (Brochier et al., Sci. Data, 2018)&lt;/li&gt;
&lt;li&gt;Dataset 3: time interval task (Meirhaeghe et al., Neuron, 2021)&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;dataset-1-reaching-task&#34;&gt;Dataset 1: reaching task&lt;/h2&gt;
&lt;h5 id=&#34;goal-decode-intended-arm-movements-from-motor-cortical-activity&#34;&gt;Goal: decode intended arm movements from motor cortical activity&lt;/h5&gt;
&lt;p&gt;&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/centerout-task.png&#34; height=&#34;200&#34; /&gt;&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/trajectories.png&#34; height=&#34;300&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hatsopoulos, Joshi, and O&amp;rsquo;Leary (2004) &lt;a href=&#34;https://journals.physiology.org/doi/full/10.1152/jn.01245.2003&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi:10.1152/jn.01245.2003&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;!--
---

## Dataset 1: reaching task

&lt;img class=&#34;fragment&#34; data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/dataset1_fig1.jpeg&#34; height=&#34;350&#34; /&gt; &lt;img class=&#34;fragment&#34; data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/dataset1_fig4.jpeg&#34; height=&#34;350&#34; /&gt;

&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah
blah blas blah&lt;/p&gt;

&lt;/aside&gt; --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;dataset-2-grasping-task&#34;&gt;Dataset 2: grasping task&lt;/h2&gt;
&lt;h5 id=&#34;goal-predicting-animals-reaction-times-from-neural-preparatory-activity&#34;&gt;Goal: predicting animals’ reaction times from neural preparatory activity&lt;/h5&gt;
&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset2_grasping-task/reach2grasp-task.png&#34; height=&#34;250&#34; /&gt;
&lt;p&gt;Brochier, Zehl, Hao, Duret, Sprenger, Denker, Grün, &amp;amp; Riehle (2018) Scientific Data 5 : 180055. &lt;a href=&#34;https://www.nature.com/articles/sdata201855&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi:10.1038/sdata.2018.55&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;dataset-3-time-interval-task&#34;&gt;Dataset 3: time interval task&lt;/h2&gt;
&lt;h5 id=&#34;goal-relating-neural-dynamics-to-animals-behavioral-performance&#34;&gt;Goal: relating neural dynamics to animals’ behavioral performance&lt;/h5&gt;
&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset3_time-interval-task/dataset3_fig1A.png&#34; height=&#34;300&#34; /&gt;
&lt;p&gt;Meirhaeghe, Sohn, and Jazayeri (2021) &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.03.10.434831v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi:10.1016/j.neuron.2021.08.025 &lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;home page: &lt;a href=&#34;https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Contact us @ &lt;a href=&#34;mailto:nmrghe@gmail.com,laurent.perrinet@univ-amu.fr&#34;&gt;nicolas.meirhaeghe@univ-amu.fr, laurent.perrinet@univ-amu.fr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub repository: &lt;a href=&#34;https://github.com/CONECT-INT/2022_CENTURI-SummerSchool&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/CONECT-INT/2022_CENTURI-SummerSchool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Computational Neuroscience projet</title>
      <link>https://conect-int.github.io/slides/2023-06-19-conect-centuri-summer-school/</link>
      <pubDate>Mon, 20 Jun 2022 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/slides/2023-06-19-conect-centuri-summer-school/</guid>
      <description>
&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/open-book.jpg&#34;
  &gt;

&lt;h1 id=&#34;computational-neuroscience-projet&#34;&gt;Computational Neuroscience projet&lt;/h1&gt;
&lt;h2 id=&#34;centuri-summer-school&#34;&gt;CENTURI Summer school&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://conect-int.github.io/talk/2023-06-20-conect-at-the-centuri-summer-school/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://conect-int.github.io/talk/2023-06-20-conect-at-the-centuri-summer-school/&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;li&gt;Hi, we are LP and NM and we look forward to start working with you on this project&lt;/li&gt;
&lt;li&gt;as part of the CENTURI summer school - and we would like to thank the organizers of the school&amp;hellip;&lt;/li&gt;
&lt;li&gt;In this short presentation, we will present the challenges that we want to tackle and which we named&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;who-are-we&#34;&gt;Who are we?&lt;/h2&gt;
 &lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;&lt;img data-src=&#34;https://conect-int.github.io/authors/nicolas-meirhaeghe/avatar.jpg&#34; height=&#34;200&#34; /&gt;&lt;/th&gt;
    &lt;th&gt;&lt;img data-src=&#34;https://conect-int.github.io/authors/laurent-u-perrinet/avatar.jpg&#34; height=&#34;200&#34; /&gt;&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Nicolas&lt;BR&gt;Meirhaeghe&lt;/td&gt;
    &lt;td&gt;Laurent&lt;BR&gt;Perrinet&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;challenge-brain-decoding&#34;&gt;Challenge: brain decoding&lt;/h2&gt;
&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/decoding.png&#34; height=&#34;420&#34; /&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;our brains light up billions of cells in a structured way,&lt;/li&gt;
&lt;li&gt;neural activity is in majority carried by action potentials, or &lt;em&gt;spikes&lt;/em&gt;,&lt;/li&gt;
&lt;li&gt;we wish to better understand this structure by using machine learning.&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;objectives&#34;&gt;Objectives&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Learn computational methods to interpret and interrogate neural data&lt;/li&gt;
&lt;li&gt;Learn to reduce the complexity of high-dimensional neural data&lt;/li&gt;
&lt;li&gt;Learn statistical approaches to perform hypothesis-testing on neural data&lt;/li&gt;
&lt;li&gt;Learn the principles of decoding analyses to relate neural data to behavioral data&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTES&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;datasets&#34;&gt;Datasets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Dataset 1: reaching task (Hatsopoulos et al., J. Neurophysiol., 2004)&lt;/li&gt;
&lt;li&gt;Dataset 2: grasping task (Brochier et al., Sci. Data, 2018)&lt;/li&gt;
&lt;li&gt;Dataset 3: time interval task (Meirhaeghe et al., Neuron, 2021)&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;dataset-1-reaching-task&#34;&gt;Dataset 1: reaching task&lt;/h2&gt;
&lt;h5 id=&#34;goal-decode-intended-arm-movements-from-motor-cortical-activity&#34;&gt;Goal: decode intended arm movements from motor cortical activity&lt;/h5&gt;
&lt;p&gt;&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/centerout-task.png&#34; height=&#34;200&#34; /&gt;&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/trajectories.png&#34; height=&#34;300&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hatsopoulos, Joshi, and O&amp;rsquo;Leary (2004) &lt;a href=&#34;https://journals.physiology.org/doi/full/10.1152/jn.01245.2003&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi:10.1152/jn.01245.2003&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;dataset-2-time-interval-task&#34;&gt;Dataset 2: time interval task&lt;/h2&gt;
&lt;h5 id=&#34;goal-relating-neural-dynamics-to-animals-behavioral-performance&#34;&gt;Goal: relating neural dynamics to animals’ behavioral performance&lt;/h5&gt;
&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset3_time-interval-task/dataset3_fig1A.png&#34; height=&#34;300&#34; /&gt;
&lt;p&gt;Meirhaeghe, Sohn, and Jazayeri (2021) &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.03.10.434831v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi:10.1016/j.neuron.2021.08.025 &lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;home page: &lt;a href=&#34;https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Contact us @ &lt;a href=&#34;mailto:nmrghe@gmail.com,laurent.perrinet@univ-amu.fr&#34;&gt;nicolas.meirhaeghe@univ-amu.fr, laurent.perrinet@univ-amu.fr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub repository: &lt;a href=&#34;https://github.com/CONECT-INT/2023_CENTURI-SummerSchool&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/CONECT-INT/2023_CENTURI-SummerSchool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2022-05-12 : A CONECT seminar &#34;Global organization of neuronal activity only requires unstructured local connectivity&#34; (David Dahmen)</title>
      <link>https://conect-int.github.io/talk/2022-05-12-a-conect-seminar-global-organization-of-neuronal-activity-only-requires-unstructured-local-connectivity-david-dahmen/</link>
      <pubDate>Thu, 12 May 2022 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2022-05-12-a-conect-seminar-global-organization-of-neuronal-activity-only-requires-unstructured-local-connectivity-david-dahmen/</guid>
      <description>&lt;p&gt;During this CONECT seminar, &lt;a href=&#34;https://scholar.google.com/citations?user=AZa4K5QAAAAJ&amp;amp;hl=fr&amp;amp;oi=ao&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;David Dahmen&lt;/a&gt; did present his recent work on &amp;ldquo;&lt;strong&gt;Global organization of neuronal activity only requires unstructured local connectivity&lt;/strong&gt;&amp;rdquo;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/35049496/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dahmen D, Layer M, Deutz L, Dąbrowska PA, Voges N, von Papen M, Brochier T, Riehle A, Diesmann M, Grün S, Helias M. Elife. 2022 Jan 20;11:e68422&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Dr. &lt;a href=&#34;https://www.fz-juelich.de/SharedDocs/Personen/INM/INM-6/EN/staff/Dahmen_David.html?nn=724620&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;David Dahmen&lt;/a&gt; is a PostDoc at the Research Centre Jülich (Institute of Neuroscience and Medicine (INM-6), Computational and Systems Neuroscience &amp;amp; Institute for Advanced Simulation (IAS-6), Theoretical Neuroscience &amp;amp; JARA-Institut Brain structure-function relationships (INM-10)).
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>2022-03-04 : INT Seminar - &#34;Unifying Different Psychometric Methods : Theory and Experiment&#34; (Jonathan Vacher)</title>
      <link>https://conect-int.github.io/talk/2022-03-04-int-seminar-unifying-different-psychometric-methods-theory-and-experiment-jonathan-vacher/</link>
      <pubDate>Fri, 04 Mar 2022 14:30:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2022-03-04-int-seminar-unifying-different-psychometric-methods-theory-and-experiment-jonathan-vacher/</guid>
      <description>&lt;p&gt;During a seminar at the Institute of Neurosciences Timone in Marseille, &lt;a href=&#34;https://jonathanvacher.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonathan Vacher&lt;/a&gt; will present his recent work on &amp;ldquo;&lt;strong&gt;Unifying Different Psychometric Methods : Theory and Experiment&lt;/strong&gt;&amp;rdquo;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The two-alternative forced choice (2AFC) paradigm is one of the main methods used to measure perceptual thresholds and biases. Measurements from a 2AFC experiment can be modelled using signal detection theory (SDT) from which the psychometric function can be derived theoretically. Recent efforts to combine SDT with Bayesian probabilities has linked thresholds and biases to hypothesized prior knowledge and optimal encoding/decoding [1]. From another perspective, the maximum likelihood difference scaling (MLDS) paradigm is a more recent method that allows the experimenter to estimate a perceptual scale that links a physical property to a psychological dimension [2]. Such a perceptual scale is obtained from the comparison of relative differences between pairs of stimuli. Here again, the underlying model can be understood in terms of SDT and Bayesian probabilities. However, no comparison between MLDS and 2AFC measurements has been performed yet. Here, we introduce the theory that unifies those measurements and we present some preliminary experimental results. In this context, we further explore how MLDS measurements could help to understand the perception of more complex textures generated from the statistic of deep neural network features [3].&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;[1] Wei, X. X., &amp;amp; Stocker, A. A. (2017). Lawful relation between perceptual bias and discriminability. Proceedings of the National Academy of Sciences, 114(38), 10244-10249.&lt;/p&gt;
&lt;p&gt;[2] Maloney, L. T., &amp;amp; Yang, J. N. (2003). Maximum likelihood difference scaling. Journal of Vision, 3(8):5, 573-585.&lt;/p&gt;
&lt;p&gt;[3] Vacher, J. &amp;amp; Davila, A., Kohn, A. &amp;amp; Coen-Cagli, R. (2021). Texture Interpolation for Probing Visual Perception. Advances in Neural Information Processing Systems, 33.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Dr. &lt;a href=&#34;https://jonathanvacher.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonathan Vacher&lt;/a&gt; was a student at École Normale Supérieure de Cachan (now &lt;a href=&#34;http://www.ens-paris-saclay.fr/en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Saclay&lt;/a&gt;) where he pursued a degree in mathematics and applied mathematics. He completed his bachelor&amp;rsquo;s and master&amp;rsquo;s degree with a specialty in computational imaging and machine learning (&lt;a href=&#34;http://math.ens-paris-saclay.fr/version-francaise/formations/master-mva/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Master MVA&lt;/a&gt;). He started a multidisciplinary PhD in mathematics (&lt;a href=&#34;http://www.dauphine.fr/en/research/research-centers/ceremade-umr-7534.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paris Dauphine University, CEREMADE)&lt;/a&gt; and neuroscience (&lt;a href=&#34;https://neuropsi.cnrs.fr/fr/icn/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNRS, UNIC&lt;/a&gt;) under the supervision of &lt;a href=&#34;http://www.gpeyre.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gabriel Peyré&lt;/a&gt; and &lt;a href=&#34;https://www.unic.cnrs-gif.fr/people/cyril_monier/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cyril Monier&lt;/a&gt;. Then, Jonathan was a postdoc at Albert Einstein College of Medicine in New-York between 2017 and 2020 while initiating a collaboration with Pascal Mamassian from the Laboratoire des Systèmes Perceptifs ()École Normale Supérieure de Paris) where he is currently a postdoc.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>2022-02-24 : CONECT Seminar - &#34;Explainable AI for computational auditory neurosciences&#34; (Etienne Thoret)</title>
      <link>https://conect-int.github.io/talk/2022-02-24-conect-seminar-explainable-ai-for-computational-auditory-neurosciences-etienne-thoret/</link>
      <pubDate>Thu, 24 Feb 2022 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2022-02-24-conect-seminar-explainable-ai-for-computational-auditory-neurosciences-etienne-thoret/</guid>
      <description>&lt;p&gt;Etienne Thoret (ILCB/PRISM/LIS/AMU) kindly accepted to present his research project during our novel series of CONECT-core © seminars (=seminars open to all but focused on the core theoretical scientific questions of the CONECT members):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Explainable AI for computational auditory neurosciences&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Machine learning and deep neural networks have been raised as compelling models to simulate a broad range of tasks on signals: from classification of sound events to the prediction of human physiological state from electrophysiological data. But what do we really understand about these models and how do they process the information they have been trained to process? As users, we often use them as tools without precisely understanding their mechanistic and representational underpinnings. In this talk, I&amp;rsquo;ll present recent works on how we can take part of these computational systems to answer fundamental research mysteries on auditory perception, speech production and cerebral processing. Beyond acoustics and sound perception, these techniques can find applications for the modeling of a variety of systems, including computational vision in robotics, haptics and clinical applications.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>2021-12-10 : CONECT seminar - &#34;Sequence anticipation and STDP emerge from a voltage-based predictive learning rule&#34; (Matteo Saponati)</title>
      <link>https://conect-int.github.io/talk/2021-12-10-conect-seminar-sequence-anticipation-and-stdp-emerge-from-a-voltage-based-predictive-learning-rule-matteo-saponati/</link>
      <pubDate>Fri, 10 Dec 2021 11:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2021-12-10-conect-seminar-sequence-anticipation-and-stdp-emerge-from-a-voltage-based-predictive-learning-rule-matteo-saponati/</guid>
      <description>&lt;p&gt;During a seminar at the Institute of Neurosciences Timone in Marseille, &lt;a href=&#34;https://github.com/matteosaponati&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Matteo Saponati&lt;/a&gt;, will present his recent work showing that &amp;ldquo;&lt;strong&gt;Sequence anticipation and STDP emerge from a voltage-based predictive learning rule&lt;/strong&gt;&amp;rdquo;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Intelligent behavior depends on the brain’s ability to anticipate future events. However, the learning rules that enable neurons to predict and fire ahead of sensory inputs remain largely unknown. We propose a plasticity rule based on predictive processing, where the neuron learns a low-rank model of the synaptic input dynamics in its membrane potential. Neurons thereby amplify those synapses that maximally predict other synaptic inputs based on their temporal relations, which provide a solution to an optimization problem that can be implemented at the single-neuron level using only local information. Consequently, neurons learn sequences over long timescales and shift their spikes towards the first inputs in a sequence. We show that this mechanism can explain the development of anticipatory motion signaling and recall in the visual system. Furthermore, we demonstrate that the learning rule gives rise to several experimentally observed STDP (spike-timing-dependent plasticity) mechanisms. These findings suggest prediction as a guiding principle to orchestrate learning and synaptic plasticity in single neurons.
&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.10.31.466667v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.biorxiv.org/content/10.1101/2021.10.31.466667v1&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;when: Friday 10th of December at 11am&lt;/li&gt;
&lt;li&gt;where: Salle Laurent Vinay at the &lt;a href=&#34;https://www.int.univ-amu.fr/contact&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Institute of Neurosciences Timone&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;a href=&#34;https://github.com/matteosaponati&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Matteo Saponati&lt;/a&gt; is a PhD candidate at &lt;a href=&#34;https://www.esi-frankfurt.de/research/vinck-lab/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ernst Strüngmann Institute (ESI) for Neuroscience - IMPRS for Neural Circuits&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>2020-09-11 : CONECT seminar - &#34;Feedforward and feedback processes in visual recognition&#34; (T Serre)</title>
      <link>https://conect-int.github.io/talk/2020-09-11-conect-seminar-feedforward-and-feedback-processes-in-visual-recognition-t-serre/</link>
      <pubDate>Fri, 11 Sep 2020 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2020-09-11-conect-seminar-feedforward-and-feedback-processes-in-visual-recognition-t-serre/</guid>
      <description>&lt;p&gt;During a seminar at the Institute of Neurosciences Timone in Marseille, &lt;a href=&#34;http://serre-lab.clps.brown.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Thomas Serre&lt;/a&gt; will present his recent work on &amp;ldquo;Feedforward and feedback processes in visual recognition&amp;rdquo;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Progress in deep learning has spawned great successes in many engineering applications. As a prime example, convolutional neural networks, a type of feedforward neural networks, are now approaching – and sometimes even surpassing – human accuracy on a variety of visual recognition tasks. In this talk, however, I will show that these neural networks and their recent extensions exhibit a limited ability to solve seemingly simple visual reasoning problems involving incremental grouping, similarity, and spatial relation judgments. Our group has developed a recurrent network model of classical and extra-classical receptive fields that is constrained by the anatomy and physiology of the visual cortex. The model was shown to account for diverse visual illusions providing computational evidence for a novel canonical circuit that is shared across visual modalities. I will show that this computational neuroscience model can be turned into a modern end-to-end trainable deep recurrent network architecture that addresses some of the shortcomings exhibited by state-of-the-art feedforward networks for solving complex visual reasoning tasks. This suggests that neuroscience may contribute powerful new ideas and approaches to computer science and artificial intelligence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Dr. &lt;a href=&#34;http://serre-lab.clps.brown.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Thomas Serre&lt;/a&gt; is an Associate Professor in Cognitive Linguistic and Psychological Sciences and an affiliate of the Carney Institute for Brain Science at Brown University. He received a Ph.D. in Neuroscience from MIT in 2006 and an MSc in EECS from Télécom Bretagne (France) in 2000. His research seeks to understand the neural computations supporting visual perception and has been featured in the BBC series “Visions from the Future” and other news articles (The Economist, New Scientist, Scientific American, IEEE Computing in Science and Technology, Technology Review and Slashdot). Dr. Serre is the Faculty Director of the Center for Computation and Visualization and the Associate Director of the Initiative for Computation in Brain and Mind at Brown University. He also holds an International Chair in AI within the Artificial and Natural Intelligence Toulouse Institute (France). Dr. Serre has served as an area chair and a senior program committee member for top-tier machine learning and computer vision conferences including AAAI, CVPR, and NeurIPS. He is currently serving as a domain expert for IARPA’s Machine Intelligence from Cortical Networks (MICrONS) program and as a scientific advisor for Vium, Inc. He was the recipient of an NSF Early Career Award as well as DARPA’s Young Faculty Award and Director’s Award.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://conect-int.github.io/slides/conect/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/slides/conect/</guid>
      <description>
&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/open-book.jpg&#34;
  &gt;

&lt;h1 id=&#34;conect&#34;&gt;CoNeCt&lt;/h1&gt;
&lt;h2 id=&#34;the-computational-neuroscience-center--int&#34;&gt;the &lt;strong&gt;Co&lt;/strong&gt;mputational &lt;strong&gt;Ne&lt;/strong&gt;uroscience &lt;strong&gt;C&lt;/strong&gt;en&lt;strong&gt;t&lt;/strong&gt;er @ INT&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://conect-int.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://conect-int.github.io&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;CONECT with one N&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;tremendous-technological-advances&#34;&gt;Tremendous technological advances&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;two photon imaging&lt;/li&gt;
&lt;li&gt;large population recording-array technologies&lt;/li&gt;
&lt;li&gt;optogenetic circuit control tools&lt;/li&gt;
&lt;li&gt;transgenic manipulations&lt;/li&gt;
&lt;li&gt;large volume circuit reconstructions&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;Tremendous technological advances over the past decade&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;These experiments have begun to produce a huge amount of data, on a broad spectrum of temporal and spatial scales,&lt;/li&gt;
&lt;li&gt;providing finer and more quantitative descriptions of the biological reality than we would have been able to dream of only a decade ago.&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;a-transdisciplinary-revolution&#34;&gt;A transdisciplinary revolution&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;across several disciplines (physics, genetics, biology, robotics, psychiatry, ..)&lt;/li&gt;
&lt;li&gt;and multiple scales (from micro to macro, from short to long-term, from theory to biology)&lt;/li&gt;
&lt;li&gt;new frontiers&lt;span class=&#34;fragment &#34; &gt;
… and new challenges
&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;daunting complexity of the biological reality revealed by these technologies highlights the importance of neurophysics&lt;/li&gt;
&lt;li&gt;to provide a conceptual bridge between abstract principles of brain function and their biological implementations within neural circuits.&lt;/li&gt;
&lt;li&gt;This revolution is accompanied by a parallel revolution in the domain of Artificial Intelligence. An exponential number of algorithms in sensory processing, such as image classification, or reinforcement learning have realized practical tools which have replaced the classical tools we were using on a daily basis by a novel range of intelligent tools of a new generation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;This is the context in which we are creating CONECT.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;conect-computational-neuroscience-center&#34;&gt;CoNeCt: &lt;strong&gt;Co&lt;/strong&gt;mputational &lt;strong&gt;Ne&lt;/strong&gt;uroscience &lt;strong&gt;C&lt;/strong&gt;en&lt;strong&gt;t&lt;/strong&gt;er&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;close collaboration between experimentalists and theoreticians&lt;/li&gt;
&lt;li&gt;share state-of-the-art (experimentalists well aware of theoretical approaches, experimental techniques for theoreticians)&lt;/li&gt;
&lt;li&gt;complementary in its purpose from neuroinformatics&amp;hellip; &lt;span class=&#34;fragment &#34; &gt;
but distinct
&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;We are convinced that close collaboration between experimentalists and theoreticians in neuroscience is essential to develop mechanistic as well as quantitative understandings of how the brain performs its functions. This is in fact a primary motivating force in establishing this center.&lt;/li&gt;
&lt;li&gt;However, for such collaborations to be effective, experimentalists must be well aware of the approaches and challenges in modeling while theoreticians must be well acquainted with the experimental techniques, their power and the challenges they present.&lt;/li&gt;
&lt;li&gt;CoNeCt has also the ambition to contribute to the training of a new generation of neuroscientists who will have all these qualities.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This approach is therefore complementary but distinct in its purpose from neuroinformatics (creation of tools for analyzing neuroscientific data) or artificial intelligence (creation of algorithms inspired by the functioning of the brain). The field of computational neuroscience is still young but its community is now structured in an autonomous community with strong interaction with the other branches of neuroscience. It is this autonomy that we want to foster at INT.
&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;objectives-of-conect&#34;&gt;Objectives of CoNeCt&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;to create a space for scientific discussion and animation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;train students and staff and attract young researchers:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;structuring the network of computational neurosciences at INT, on Timone, on AMU and in France &amp;amp; International&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;lots of work - bottom approach so far&lt;/li&gt;
&lt;li&gt;no action taken&lt;/li&gt;
&lt;li&gt;lots of work - existence of top-down initiatives&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;actions-of-conect&#34;&gt;Actions of CoNeCt&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;










  









  




&lt;div class=&#34;view-list view-list-item&#34;&gt;
  &lt;i class=&#34;far fa-newspaper pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
  &lt;a href=&#34;https://conect-int.github.io/post/actors-conect/&#34; &gt;Actors of CONECT&lt;/a&gt;

  

  

  

&lt;/div&gt;



&lt;/li&gt;
&lt;li&gt;










  









  




&lt;div class=&#34;view-list view-list-item&#34;&gt;
  &lt;i class=&#34;far fa-newspaper pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
  &lt;a href=&#34;https://conect-int.github.io/post/objectives-conect/&#34; &gt;Objectives of CONECT&lt;/a&gt;

  

  

  

&lt;/div&gt;



&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://conect-int.github.io/event&#34;&gt;Past events&lt;/a&gt; and future&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Actors&lt;/li&gt;
&lt;li&gt;we already organized events within or outside INT&lt;/li&gt;
&lt;li&gt;objectives : exist&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://conect-int.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://conect-int.github.io&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;mailto://int-conect@univ-amu.fr&#34;&gt;Contact us @ int-conect@univ-amu.fr!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://framateam.org/int-marseille/channels/conect&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Let&amp;rsquo;s discuss on Mattermost&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
