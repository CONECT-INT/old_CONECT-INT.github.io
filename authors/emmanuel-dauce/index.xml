<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Emmanuel Daucé | CONECT | Computational Neuroscience Center @ INT</title>
    <link>https://conect-int.github.io/authors/emmanuel-dauce/</link>
      <atom:link href="https://conect-int.github.io/authors/emmanuel-dauce/index.xml" rel="self" type="application/rss+xml" />
    <description>Emmanuel Daucé</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 12 Jun 2023 09:00:00 +0000</lastBuildDate>
    <image>
      <url>https://conect-int.github.io/authors/emmanuel-dauce/avatar_hu1fde9367436786238e788425b403acc0_7959_270x270_fill_q75_lanczos_center.jpg</url>
      <title>Emmanuel Daucé</title>
      <link>https://conect-int.github.io/authors/emmanuel-dauce/</link>
    </image>
    
    <item>
      <title>2023-06-12: CONECT Workshop on Learning</title>
      <link>https://conect-int.github.io/talk/2023-06-12-conect-workshop-on-learning/</link>
      <pubDate>Mon, 12 Jun 2023 09:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2023-06-12-conect-workshop-on-learning/</guid>
      <description>&lt;h1 id=&#34;conect-workshop-active-learning-in-brains-and-machines&#34;&gt;CONECT Workshop &lt;em&gt;Active learning in brains and machines&lt;/em&gt;&lt;/h1&gt;
&lt;p&gt;When? &lt;em&gt;12th of June 2023&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Where? &lt;em&gt;Campus Timone (room Gastaut), Aix-Marseille Université&lt;/em&gt;, 27 Boulevard Jean Moulin, 13005 Marseille&lt;/p&gt;
&lt;h2 id=&#34;topics&#34;&gt;Topics&lt;/h2&gt;
&lt;p&gt;In biology, a major trait of neural systems is the capability to &lt;em&gt;learn&lt;/em&gt;, that is, to adapt its behavior to the environment it interacts with. Recent advances in machine learning and deep learning have, in parallel, contributed to formulate learning in terms of optimizing performance under task-specific domains.&lt;/p&gt;
&lt;p&gt;While each field inspires the other, there is still a gap in our understanding of how learning in machines may compare or even relate to learning in biology. The goal of this workshop is to allow people from both computational and experimental sides to understand current research achievements and challenges about &lt;em&gt;active learning in brains and machines&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&#34;program&#34;&gt;PROGRAM&lt;/h3&gt;
&lt;p&gt;9:00 : Welcome &amp;amp; Introduction&lt;/p&gt;
&lt;h4 id=&#34;session-1--encoding-of-neuronal-representations-chair-emmanuel-daucé&#34;&gt;Session 1 : Encoding of neuronal representations (chair: Emmanuel Daucé)&lt;/h4&gt;
&lt;p&gt;9:15 : &lt;strong&gt;&lt;strong&gt;Alexandre Pitti&lt;/strong&gt;&lt;/strong&gt; (ETIS, CY-U, Cergy Pontoise): &amp;ldquo;Neuro-inspired mechanisms for sensorimotor and syntactic learning in language&amp;rdquo;&lt;/p&gt;
&lt;p&gt;9:55 : &lt;strong&gt;Matthieu Gilson &amp;amp; Laurie Mifsud&lt;/strong&gt; (INT, Marseille) &amp;ldquo;Covariance-based processing in bio-inspired neuronal network&amp;rdquo;&lt;/p&gt;
&lt;p&gt;10:15 : &lt;strong&gt;Antoine Grimaldi&lt;/strong&gt; (INT, Marseille) &amp;ldquo;Learning in networks of spiking neurons with heterogeneous delays&amp;rdquo;&lt;/p&gt;
&lt;p&gt;10:35 : coffee break&lt;/p&gt;
&lt;h4 id=&#34;session-2--learning-action-selection-chair-matthieu-gilson&#34;&gt;Session 2 : Learning action selection (chair: Matthieu Gilson)&lt;/h4&gt;
&lt;p&gt;11:00 : &lt;strong&gt;&lt;strong&gt;Jorge Ramirez Ruiz&lt;/strong&gt;&lt;/strong&gt; (Univ Pompeu Fabra, Barcelona) &amp;ldquo;Path occcupancy maximization principle&amp;rdquo;&lt;/p&gt;
&lt;p&gt;11:40 : &lt;strong&gt;Nicolas Meirhaeghe&lt;/strong&gt; (INT, Marseille) : &amp;ldquo;Bayesian Computation through Cortical Latent Dynamics&amp;rdquo;&lt;/p&gt;
&lt;p&gt;12:00 : &lt;strong&gt;Emmanuel Daucé &amp;amp; Hamza Oueld&lt;/strong&gt; (INT, Marseille) : &amp;ldquo;Principles of model-driven active sampling in the brain&amp;rdquo;&lt;/p&gt;
&lt;p&gt;12:30 : Meal&lt;/p&gt;
&lt;h4 id=&#34;session-3--neuronal-basis-of-vocal-representation-chair-simon-nougaret&#34;&gt;Session 3 : Neuronal basis of vocal representation (chair: Simon Nougaret)&lt;/h4&gt;
&lt;p&gt;14:00 : &lt;strong&gt;&lt;strong&gt;Thomas Schatz&lt;/strong&gt;&lt;/strong&gt; (LIS, Marseille): &amp;ldquo;Perceptual development, unsupervised representation learning and auditory neuroscience&amp;rdquo;&lt;/p&gt;
&lt;p&gt;14:40 : &lt;strong&gt;Charly Lamothe&lt;/strong&gt; (LIS/INT, Marseille)  &amp;amp; &lt;strong&gt;Etienne Thoret&lt;/strong&gt; (PRISM/LIS/ILCB, Marseille): &amp;ldquo;Characterization of the vocal brain and brain-based voice reconstruction using machine learning and deep learning techniques&amp;rdquo;&lt;/p&gt;
&lt;p&gt;15:00 : coffee break&lt;/p&gt;
&lt;h4 id=&#34;session-4--distribution-and-integration-of-brain-functions-chair-laurent-perrinet&#34;&gt;Session 4 : Distribution and integration of brain functions (chair: Laurent Perrinet)&lt;/h4&gt;
&lt;p&gt;15:30 : &lt;strong&gt;&lt;strong&gt;Jean-Rémi King&lt;/strong&gt;&lt;/strong&gt; (Meta / CNRS): &amp;ldquo;Language in the brain and algorithms&amp;rdquo;&lt;/p&gt;
&lt;p&gt;16:10 : &lt;strong&gt;Etienne Combrisson &amp;amp; Andrea Brovelli&lt;/strong&gt; (INT, Marseille) : &amp;ldquo;Cortico-cortical interactions for goal-directed causal learning&amp;rdquo;&lt;/p&gt;
&lt;p&gt;16:30 : Round table&lt;/p&gt;
&lt;h3 id=&#34;abstracts&#34;&gt;Abstracts&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Thomas Schatz: &amp;ldquo;Perceptual development, unsupervised representation learning and auditory neuroscience&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;I will draw from ongoing research projects at the interface between developmental psychology, machine learning, and computational neuroscience, to illustrate how, in my view, perspectives from each of these fields may contribute to the others. More specifically, I will discuss how considerations from developmental psychology and computational neuroscience can inform the design of novel algorithms for the unsupervised learning of speech representations and how the study of these algorithms may, in turn, lead to a deeper understanding of dynamic signal processing in the human brain and of perceptual development in infancy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Jean-Rémi King: &amp;ldquo;Language in the brain and algorithms.&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Deep learning has recently made remarkable progress in natural language processing. Yet, the resulting algorithms fall short of the efficiency of the human brain. To bridge this gap, we here explore the similarities and differences between these two systems using large-scale datasets of magneto/electro-encephalography (M/EEG), functional Magnetic Resonance Imaging (fMRI), and intracranial recordings. After investigating where and when deep language algorithms map onto the brain, we show that enhancing these algorithms with long-range forecasts makes them more similar to the brain. Our results further reveal that, unlike current deep language models, the human brain is tuned to generate a hierarchy of long-range predictions, whereby the fronto-parietal cortices forecast more abstract and more distant representations than the temporal cortices. Overall, our studies show how the interface between AI and neuroscience clarifies the computational bases of natural language processing.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>
