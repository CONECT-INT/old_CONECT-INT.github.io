<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CONECT | Computational Neuroscience Center @ INT</title>
    <link>https://conect-int.github.io/</link>
      <atom:link href="https://conect-int.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>CONECT | Computational Neuroscience Center @ INT</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 20 Jun 2022 14:00:00 +0000</lastBuildDate>
    <image>
      <url>https://conect-int.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>CONECT | Computational Neuroscience Center @ INT</title>
      <link>https://conect-int.github.io/</link>
    </image>
    
    <item>
      <title>Why CONECT?</title>
      <link>https://conect-int.github.io/post/about-conect/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/post/about-conect/</guid>
      <description>&lt;p&gt;Neuroscience is in revolution: Over the past decade, tremendous technological advances across several disciplines have dramatically expanded the frontiers of experimentally accessible neuroscientific facts.&lt;/p&gt;
&lt;p&gt;Bridging across different spatial and temporal scales, combination of in vivo two photon imaging, large population recording-array technologies, optogenetic circuit control tools, transgenic manipulations as well as large volume circuit reconstructions are now used to examine the function, structure and dynamics of neural networks on an unprecedented level of detail and precision. Current applications of these novel techniques include sensory information processing, motor production, neural correlates of learning, memory and decision making as well as mechanisms of dysfunctions and disease. These experiments have begun to produce a huge amount of data, on a broad spectrum of temporal and spatial scales, providing finer and more quantitative descriptions of the biological reality than we would have been able to dream of only a decade ago. The daunting complexity of the biological reality revealed by these technologies highlights the importance of neurophysics to provide a conceptual bridge between abstract principles of brain function and their biological implementations within neural circuits. This revolution is accompanied by a parallel revolution in the domain of Artificial Intelligence. An exponential number of algorithms in sensory processing, such as image classification, or reinforcement learning have realized practical tools which have replaced the classical tools we were using on a daily basis by a novel range of intelligent tools of a new generation. This is the context in which we are creating CONECT.&lt;/p&gt;
&lt;p&gt;We are convinced that &lt;em&gt;&lt;strong&gt;the close collaboration between experimentalists and theoreticians in neuroscience is essential to develop mechanistic as well as quantitative understandings of how the brain performs its functions&lt;/strong&gt;&lt;/em&gt;. This is in fact a primary motivating force in establishing this center. However, for such collaborations to be effective, experimentalists must be well aware of the approaches and challenges in modeling while theoreticians must be well acquainted with the experimental techniques, their power and the challenges they present. CONECT has also the ambition to contribute to the training of a new generation of neuroscientists who will have all these qualities.&lt;/p&gt;
&lt;p&gt;This approach is therefore complementary but distinct in its purpose from neuroinformatics (creation of tools for analyzing neuroscientific data) or artificial intelligence (creation of algorithms inspired by the functioning of the brain). The field of computational neuroscience is still young but its community is now structured in an autonomous community with strong interaction with the other branches of neuroscience. It is this autonomy that we want to foster at INT.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Actors of CONECT</title>
      <link>https://conect-int.github.io/post/actors-conect/</link>
      <pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/post/actors-conect/</guid>
      <description>&lt;p&gt;Within the INT, many components of CONECT already exist, either carried by researchers in computational neurosciences or as themes strongly anchored in this field. A survey of the current situation reveals the existence of projects at different scales.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://conect-int.github.io/contact&#34;&gt;Contact&lt;/a&gt; us to be added!&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;from the cellular to the network level
&lt;ul&gt;
&lt;li&gt;deciphering the biophysical principles underlying robustness of neuronal activity using quantitative genotype-to-phenotype mapping strategies and realistic neuronal model databases (&lt;strong&gt;Jean-Marc Goaillard&lt;/strong&gt; and Fabien Tell).&lt;/li&gt;
&lt;li&gt;dynamics and function of small and large-scale neural networks (&lt;strong&gt;&lt;a href=&#34;https://conect-int.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent Perrinet&lt;/a&gt;&lt;/strong&gt; with &lt;a href=&#34;../../author/frederic-y-chavane&#34;&gt;Fr√©d√©ric Chavane&lt;/a&gt;, &lt;em&gt;&lt;a href=&#34;../../author/david-hansel&#34;&gt;David Hansel&lt;/a&gt;, Carl van Vreeswijk&lt;/em&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;from networks to mesoscopic levels :
&lt;ul&gt;
&lt;li&gt;Bayesian inference and predictive process models (&lt;strong&gt;&lt;a href=&#34;../../author/anna-montagnini&#34;&gt;Anna Montagnini&lt;/a&gt;&lt;/strong&gt;, &lt;a href=&#34;../../author/emmanuel-dauce&#34;&gt;Emmanuel Dauc√©&lt;/a&gt; and &lt;a href=&#34;https://conect-int.github.io/authors/laurent-u-perrinet/&#34;&gt;Laurent Perrinet&lt;/a&gt;), reinforcement learning, action selection, decision &lt;a href=&#34;../../author/andrea-brovelli&#34;&gt;Andrea Brovelli&lt;/a&gt; and &lt;a href=&#34;../../author/emmanuel-dauce&#34;&gt;Emmanuel Dauc√©&lt;/a&gt;), link with attentional mechanisms (Guilhem Ibos)&lt;/li&gt;
&lt;li&gt;information theory and functional connectivity for the analysis of cognitive brain networks (&lt;strong&gt;&lt;a href=&#34;../../author/andrea-brovelli&#34;&gt;Andrea Brovelli&lt;/a&gt;&lt;/strong&gt; and &lt;a href=&#34;../../author/bruno-giordano&#34;&gt;Bruno Giordano&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;deep learning for data processing (&lt;strong&gt;&lt;a href=&#34;../../author/bruno-giordano&#34;&gt;Bruno Giordano&lt;/a&gt;&lt;/strong&gt;), deep learning + neuroimaging (&lt;em&gt;in voice perception&lt;/em&gt;) (Charly Lamothe) computational neuroscience and data processing in neuroinformatics (Sylvain Takerkart, NIT platform)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;at brain level
&lt;ul&gt;
&lt;li&gt;brain anatomy, particularly as applied to the formation of cortical folding (Julien Lef√®vre with Guillaume Auzias, Sylvain Takerkart and &lt;strong&gt;&lt;a href=&#34;../../author/olivier-coulon&#34;&gt;Olivier Coulon&lt;/a&gt;&lt;/strong&gt;),&lt;/li&gt;
&lt;li&gt;the development of prognostic models of the evolution of certain pathologies (Lionel Velly, &lt;strong&gt;Sylvain Takerkart&lt;/strong&gt;),&lt;/li&gt;
&lt;li&gt;develop the collaboration of theoretical neurosciences with neuroinformatics, notably with the &lt;a href=&#34;http://www.int.univ-amu.fr/spip.php?page=plateform&amp;amp;equipe=CRISE&amp;amp;lang=fr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NIT&lt;/a&gt; (&lt;strong&gt;Sylvain Takerkart&lt;/strong&gt;, Guillaume Auzias)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A structuring of these different components through a center (independent of existing and future teams) would be a major asset to reach a new stage in the creation of INT¬≥.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Objectives of CONECT</title>
      <link>https://conect-int.github.io/post/objectives-conect/</link>
      <pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/post/objectives-conect/</guid>
      <description>&lt;p&gt;CONECT aims to serve as an incubator within INT to promote the use of methodologies developed in computational and theoretical neuroscience. It is not a service platform, but a catalyst for the creation and maturation of new multi-approach projects within INT.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;to &lt;strong&gt;create a space for scientific discussion and animation&lt;/strong&gt; :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Journal Clubs&lt;/strong&gt; dedicated to transversal aspects guided by advances in computational neurosciences, and occasionally a &amp;ldquo;BrainHack&amp;rdquo; to lift locks on the use of tools and means implemented at INT or on AMU (mesocentre), should explicitly state specialization levels (from &amp;ldquo;safe&amp;rdquo; for persons not directly in the field to more specialized levels).
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data club / Theory club&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;identify and propose &lt;strong&gt;INT seminars&lt;/strong&gt; in computational neurosciences&lt;/li&gt;
&lt;li&gt;organization of &lt;strong&gt;debates&lt;/strong&gt; on theoretical aspects related to neuroscience&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;communicate&lt;/strong&gt;: youtube (on the model of &lt;em&gt;&lt;a href=&#34;https://www.youtube.com/channel/UCCSIveazurb4qrNIV7KV9fg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WWTNS&lt;/a&gt;&lt;/em&gt;), twitter, facebook, share our own publications&lt;/li&gt;
&lt;li&gt;create &lt;strong&gt;social moments&lt;/strong&gt;: breakfasts, happy hours, retreat, pizza day,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;general public&lt;/strong&gt; : semaine du cerveau, the conversation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;train students and staff&lt;/strong&gt; and attract young researchers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Master level:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;create a space for sharing Master&amp;rsquo;s or thesis subjects to be distributed in the SdV doctoral schools but also to the &amp;ldquo;hard&amp;rdquo; sciences (ED info, engineering schools),
&lt;ul&gt;
&lt;li&gt;In addition to training in neurosciences, we could try to build on&lt;/li&gt;
&lt;li&gt;the Master Computational and Mathematical Biology (CMB, in connection with the CenTuri Institute) where there are courses in computational neurosciences (Laurent Pezard) and mathematical modeling for biology, in the broadest sense.&lt;/li&gt;
&lt;li&gt;JL is involved in a business UE and next year in a programming UE. Some courses of the Master in Cognitive Sciences of the ILCB could also be interesting (NAMES of the speakers on AI?).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; secure two scholarships for Master 2 students for 2021/2022,
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; valider en r√©union CE (&lt;strong&gt;Fr√©d√©ric Chavane&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; call for proposal - receive candidatures (09/2021 - 12/2021)&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; start (01/2022)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PhDs and above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The aim of this program is to help post-doctoral students to set up post-doctoral fellowships or to help them apply for jobs related to computational neurosciences (IR, CR, MdC, private sector, &amp;hellip;) ;&lt;/li&gt;
&lt;li&gt;courses ? training (theoretical) - see that of PhDprogram&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What can be done @ INT (open to all staff) vs @ Timone (with INS, eBrains&amp;hellip;) vs @ NeuroSchool (course for master &amp;amp; PhD program) vs @ Instituts (IA&amp;amp;Sant√©, Marseille Imaging, NeuroMarseille)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What to train on ?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Theory &amp;amp; modeling : for better understanding by all and stimulating interactions&lt;/li&gt;
&lt;li&gt;Data analysis : to help experimentalists to use advanced analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;structuring the network&lt;/strong&gt; of computational neurosciences at INT, on Timone, on AMU and in France &amp;amp; International:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SAB d√©but 2022 - HCERES Juin 2022&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SWOT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;participate in the development of INT¬≥ Projects by actively participating in the development of requests for means (ANR, Carnot Institute, foundations),&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Projects in general, in particular the &amp;lsquo;Transient&amp;rsquo; Project&lt;/li&gt;
&lt;li&gt;cooperate in writing grants specific to computational neuroscience for actors of CONECT (CRCNS, &amp;hellip;) and related to CONECT (eBrains, PEPR Neurosciences computationnelles, &amp;hellip;)&lt;/li&gt;
&lt;li&gt;coordinate activities with local partners (INS, INMED &amp;hellip;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;to elaborate a development strategy involving academic partners (bio-robotics, neurology, cognitive development, &amp;hellip;) and private partners (start-ups, new information technology sector, &amp;hellip;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;opening to Marseille and outside (Destexhe)&lt;/li&gt;
&lt;li&gt;International&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;increase the visibility&lt;/strong&gt; and attractiveness of INT in computational neurosciences&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;communicate through a dedicated space on &lt;a href=&#34;https://conect-int.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://conect-int.github.io/&lt;/a&gt; to share CONECT&amp;rsquo;s activities, regularly updated by a newsletter,&lt;/li&gt;
&lt;li&gt;Develop collaboration and visibility on AMU through the creation of a biannual conference at CIRM&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>2022-06-20: CONECT at the CENTURI summer school</title>
      <link>https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/</link>
      <pubDate>Mon, 20 Jun 2022 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/</guid>
      <description>&lt;h1 id=&#34;title-neural-computation-through-population-dynamics&#34;&gt;Title: Neural computation through population dynamics&lt;/h1&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;The CENTURI &lt;a href=&#34;https://twitter.com/hashtag/SummerSchool?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#SummerSchool&lt;/a&gt; 2022 has been launched this morning ! Rosa Cossart has welcomed all the participants this morning.üëæ&lt;br&gt;&lt;br&gt;Excited to begin these two weeks of transfer of knowledge and deep thinking at &lt;a href=&#34;https://twitter.com/univamu?ref_src=twsrc%5Etfw&#34;&gt;@univamu&lt;/a&gt;&lt;br&gt;!üëè&lt;br&gt;&lt;br&gt;For more info‚û°Ô∏è&lt;a href=&#34;https://t.co/K2oyuQWsmb&#34;&gt;https://t.co/K2oyuQWsmb&lt;/a&gt; &lt;a href=&#34;https://t.co/bAldJeyssj&#34;&gt;pic.twitter.com/bAldJeyssj&lt;/a&gt;&lt;/p&gt;&amp;mdash; CENTURI - Turing Centre for Living Systems (@centuri_ls) &lt;a href=&#34;https://twitter.com/centuri_ls/status/1538893493828997123?ref_src=twsrc%5Etfw&#34;&gt;June 20, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Program in construction - you can already check the program of the &lt;a href=&#34;https://centuri-livingsystems.org/centuri-summer-school-2022/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;summer school&lt;/a&gt; (June 20 - July 01, 2022)!
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;question&#34;&gt;Question&lt;/h2&gt;
&lt;p&gt;How does neural population dynamics relate to behaviorally-relevant computations?&lt;/p&gt;
&lt;h2 id=&#34;challenge&#34;&gt;Challenge&lt;/h2&gt;
&lt;p&gt;At any given instant, hundreds of billions of cells in our brains are lighting up in a complicated yet highly coordinated manner to give rise to our thoughts, percepts, and movements. A single neuron may be connected to thousands of other cells, sending out and receiving information through electrical impulses called spikes. From an engineering perspective, these spikes form a signal that may be viewed as a series of ones and zeros rapidly unfolding in time. Altogether, these signals reflect the ongoing computations taking place inside the nervous system, and as such, constitute a window into the brain‚Äôs inner workings. Recent advances in recording techniques have allowed experimenters to collect data from hundreds to thousands of neurons simultaneously while animals perform simple tasks. Dealing with such high-dimensional data poses important technical challenges that require elaborate methods for data mining and analysis. In this project, students will deal with datasets of increasing complexity and develop a set of analyses to extract meaningful information from the data.&lt;/p&gt;
&lt;h2 id=&#34;type-of-data&#34;&gt;Type of data&lt;/h2&gt;
&lt;p&gt;Data that will be shared by the teaching staff, under the BIDS standard data organization which is currently being extended to electrophysiology data by the members of the INT and the CONECT team. The data we will use consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;publicly available recordings from the dorsomedial frontal cortex of NHPs performing a time-interval reproduction task (&lt;a href=&#34;https://github.com/jazlab/Meirhaeghe2021&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/jazlab/Meirhaeghe2021&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;publicly available recordings from the motor cortex (M1/PMd) during an instructed reach-to-grasp task (&lt;a href=&#34;https://www.nature.com/articles/sdata201855&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.nature.com/articles/sdata201855&lt;/a&gt;, available at the following URL in BIDS: &lt;a href=&#34;https://gin.g-node.org/sprenger/multielectrode_grasp/src/bep_animalephys&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gin.g-node.org/sprenger/multielectrode_grasp/src/bep_animalephys&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.03.30.437692v5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.biorxiv.org/content/10.1101/2021.03.30.437692v5&lt;/a&gt; : V1, gratings-like, natural stimulations : extracellular electrophy recordings in cat V1&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;p&gt;Data visualisation, neural decoding, principal component analysis, kinematic and geometric analyses of neural trajectories in high-dimensional space, hypothesis-testing, null distributions and statistics&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Computational Neuroscience projet</title>
      <link>https://conect-int.github.io/slides/2022-06-20-conect-centuri-summer-school/</link>
      <pubDate>Mon, 20 Jun 2022 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/slides/2022-06-20-conect-centuri-summer-school/</guid>
      <description>
&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/open-book.jpg&#34;
  &gt;

&lt;h1 id=&#34;computational-neuroscience-projet&#34;&gt;Computational Neuroscience projet&lt;/h1&gt;
&lt;h2 id=&#34;centuri-summer-school&#34;&gt;CENTURI Summer school&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;li&gt;Hi, we are LP and NM and we look forward to start working with you on this project&lt;/li&gt;
&lt;li&gt;as part of the CENTURI summer school - and we would like to thank the organizers of the school&amp;hellip;&lt;/li&gt;
&lt;li&gt;In this short presentation, we will present the challenges that we want to tackle and which we named&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;who-are-we&#34;&gt;Who are we?&lt;/h2&gt;
 &lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;&lt;img data-src=&#34;https://conect-int.github.io/authors/nicolas-meirhaeghe/avatar.jpg&#34; height=&#34;200&#34; /&gt;&lt;/th&gt;
    &lt;th&gt;&lt;img data-src=&#34;https://conect-int.github.io/authors/laurent-u-perrinet/avatar.jpg&#34; height=&#34;200&#34; /&gt;&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Nicolas&lt;BR&gt;Meirhaeghe&lt;/td&gt;
    &lt;td&gt;Laurent&lt;BR&gt;Perrinet&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;challenge-brain-decoding&#34;&gt;Challenge: brain decoding&lt;/h2&gt;
&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/decoding.png&#34; height=&#34;420&#34; /&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;our brains light up billions of cells in a structured way,&lt;/li&gt;
&lt;li&gt;neural activity is in majority carried by action potentials, or &lt;em&gt;spikes&lt;/em&gt;,&lt;/li&gt;
&lt;li&gt;we wish to better understand this structure by using machine learning.&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;objectives&#34;&gt;Objectives&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Learn computational methods to interpret and interrogate neural data&lt;/li&gt;
&lt;li&gt;Learn to reduce the complexity of high-dimensional neural data&lt;/li&gt;
&lt;li&gt;Learn statistical approaches to perform hypothesis-testing on neural data&lt;/li&gt;
&lt;li&gt;Learn the principles of decoding analyses to relate neural data to behavioral data&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;2 MINUTES&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;datasets&#34;&gt;Datasets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Dataset 1: reaching task (Hatsopoulos et al., J. Neurophysiol., 2004)&lt;/li&gt;
&lt;li&gt;Dataset 2: grasping task (Brochier et al., Sci. Data, 2018)&lt;/li&gt;
&lt;li&gt;Dataset 3: time interval task (Meirhaeghe et al., Neuron, 2021)&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;dataset-1-reaching-task&#34;&gt;Dataset 1: reaching task&lt;/h2&gt;
&lt;h5 id=&#34;goal-decode-intended-arm-movements-from-motor-cortical-activity&#34;&gt;Goal: decode intended arm movements from motor cortical activity&lt;/h5&gt;
&lt;p&gt;&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/centerout-task.png&#34; height=&#34;200&#34; /&gt;&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/trajectories.png&#34; height=&#34;300&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hatsopoulos, Joshi, and O&amp;rsquo;Leary (2004) &lt;a href=&#34;https://journals.physiology.org/doi/full/10.1152/jn.01245.2003&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi:10.1152/jn.01245.2003&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;!--
---

## Dataset 1: reaching task

&lt;img class=&#34;fragment&#34; data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/dataset1_fig1.jpeg&#34; height=&#34;350&#34; /&gt; &lt;img class=&#34;fragment&#34; data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset1_reaching-task/dataset1_fig4.jpeg&#34; height=&#34;350&#34; /&gt;

&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah
blah blas blah&lt;/p&gt;

&lt;/aside&gt; --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;dataset-2-grasping-task&#34;&gt;Dataset 2: grasping task&lt;/h2&gt;
&lt;h5 id=&#34;goal-predicting-animals-reaction-times-from-neural-preparatory-activity&#34;&gt;Goal: predicting animals‚Äô reaction times from neural preparatory activity&lt;/h5&gt;
&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset2_grasping-task/reach2grasp-task.png&#34; height=&#34;250&#34; /&gt;
&lt;p&gt;Brochier, Zehl, Hao, Duret, Sprenger, Denker, Gr√ºn, &amp;amp; Riehle (2018) Scientific Data 5 : 180055. &lt;a href=&#34;https://www.nature.com/articles/sdata201855&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi:10.1038/sdata.2018.55&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;dataset-3-time-interval-task&#34;&gt;Dataset 3: time interval task&lt;/h2&gt;
&lt;h5 id=&#34;goal-relating-neural-dynamics-to-animals-behavioral-performance&#34;&gt;Goal: relating neural dynamics to animals‚Äô behavioral performance&lt;/h5&gt;
&lt;img data-src=&#34;https://raw.githubusercontent.com/CONECT-INT/2022_CENTURI-SummerSchool/main/datasets/dataset3_time-interval-task/dataset3_fig1A.png&#34; height=&#34;300&#34; /&gt;
&lt;p&gt;Meirhaeghe, Sohn, and Jazayeri (2021) &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.03.10.434831v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi:10.1016/j.neuron.2021.08.025 &lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;&lt;strong&gt;1 MINUTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;blah blas blah&lt;/p&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;home page: &lt;a href=&#34;https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://conect-int.github.io/talk/2022-06-20-conect-at-the-centuri-summer-school/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Contact us @ &lt;a href=&#34;mailto:nmrghe@gmail.com,laurent.perrinet@univ-amu.fr&#34;&gt;nicolas.meirhaeghe@univ-amu.fr, laurent.perrinet@univ-amu.fr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub repository: &lt;a href=&#34;https://github.com/CONECT-INT/2022_CENTURI-SummerSchool&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/CONECT-INT/2022_CENTURI-SummerSchool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2022-06-16: CONECT at the CENTURI summer school</title>
      <link>https://conect-int.github.io/talk/2022-06-16-conect-at-the-centuri-summer-school/</link>
      <pubDate>Thu, 16 Jun 2022 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2022-06-16-conect-at-the-centuri-summer-school/</guid>
      <description>&lt;h1 id=&#34;title-neural-computation-through-population-dynamics&#34;&gt;Title: Neural computation through population dynamics&lt;/h1&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Program in construction - you can already check the program of the &lt;a href=&#34;https://centuri-livingsystems.org/centuri-summer-school-2022/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;summer school&lt;/a&gt; (June 20 - July 01, 2022)!
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;question&#34;&gt;Question&lt;/h2&gt;
&lt;p&gt;How does neural population dynamics relate to behaviorally-relevant computations?&lt;/p&gt;
&lt;h2 id=&#34;challenge&#34;&gt;Challenge&lt;/h2&gt;
&lt;p&gt;At any given instant, hundreds of billions of cells in our brains are lighting up in a complicated yet highly coordinated manner to give rise to our thoughts, percepts, and movements. A single neuron may be connected to thousands of other cells, sending out and receiving information through electrical impulses called spikes. From an engineering perspective, these spikes form a signal that may be viewed as a series of ones and zeros rapidly unfolding in time. Altogether, these signals reflect the ongoing computations taking place inside the nervous system, and as such, constitute a window into the brain‚Äôs inner workings. Recent advances in recording techniques have allowed experimenters to collect data from hundreds to thousands of neurons simultaneously while animals perform simple tasks. Dealing with such high-dimensional data poses important technical challenges that require elaborate methods for data mining and analysis. In this project, students will deal with datasets of increasing complexity and develop a set of analyses to extract meaningful information from the data.&lt;/p&gt;
&lt;h2 id=&#34;type-of-data&#34;&gt;Type of data&lt;/h2&gt;
&lt;p&gt;Data that will be shared by the teaching staff, under the BIDS standard data organization which is currently being extended to electrophysiology data by the members of the INT and the CONECT team. The data we will use consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;publicly available recordings from the dorsomedial frontal cortex of NHPs performing a time-interval reproduction task (&lt;a href=&#34;https://github.com/jazlab/Meirhaeghe2021&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/jazlab/Meirhaeghe2021&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;publicly available recordings from the motor cortex (M1/PMd) during an instructed reach-to-grasp task (&lt;a href=&#34;https://www.nature.com/articles/sdata201855&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.nature.com/articles/sdata201855&lt;/a&gt;, available at the following URL in BIDS: &lt;a href=&#34;https://gin.g-node.org/sprenger/multielectrode_grasp/src/bep_animalephys&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://gin.g-node.org/sprenger/multielectrode_grasp/src/bep_animalephys&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.03.30.437692v5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.biorxiv.org/content/10.1101/2021.03.30.437692v5&lt;/a&gt; : V1, gratings-like, natural stimulations : extracellular electrophy recordings in cat V1&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;p&gt;Data visualisation, neural decoding, principal component analysis, kinematic and geometric analyses of neural trajectories in high-dimensional space, hypothesis-testing, null distributions and statistics&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2022-05-12 : A CONECT seminar &#34;Global organization of neuronal activity only requires unstructured local connectivity&#34; (David Dahmen)</title>
      <link>https://conect-int.github.io/talk/2022-05-12-a-conect-seminar-global-organization-of-neuronal-activity-only-requires-unstructured-local-connectivity-david-dahmen/</link>
      <pubDate>Thu, 12 May 2022 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2022-05-12-a-conect-seminar-global-organization-of-neuronal-activity-only-requires-unstructured-local-connectivity-david-dahmen/</guid>
      <description>&lt;p&gt;During this CONECT seminar, &lt;a href=&#34;https://jonathanvacher.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;David Dahmen&lt;/a&gt; did present his recent work on &amp;ldquo;&lt;strong&gt;Global organization of neuronal activity only requires unstructured local connectivity&lt;/strong&gt;&amp;rdquo;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/35049496/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dahmen D, Layer M, Deutz L, DƒÖbrowska PA, Voges N, von Papen M, Brochier T, Riehle A, Diesmann M, Gr√ºn S, Helias M. Elife. 2022 Jan 20;11:e68422&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Dr. &lt;a href=&#34;https://www.fz-juelich.de/SharedDocs/Personen/INM/INM-6/EN/staff/Dahmen_David.html?nn=724620&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;David Dahmen&lt;/a&gt; is a PostDoc at the Research Centre J√ºlich (Institute of Neuroscience and Medicine (INM-6), Computational and Systems Neuroscience &amp;amp; Institute for Advanced Simulation (IAS-6), Theoretical Neuroscience &amp;amp; JARA-Institut Brain structure-function relationships (INM-10)).
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>2022-03-04 : INT Seminar - &#34;Unifying Different Psychometric Methods : Theory and Experiment&#34; (Jonathan Vacher)</title>
      <link>https://conect-int.github.io/talk/2022-03-04-int-seminar-unifying-different-psychometric-methods-theory-and-experiment-jonathan-vacher/</link>
      <pubDate>Fri, 04 Mar 2022 14:30:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2022-03-04-int-seminar-unifying-different-psychometric-methods-theory-and-experiment-jonathan-vacher/</guid>
      <description>&lt;p&gt;During a seminar at the Institute of Neurosciences Timone in Marseille, &lt;a href=&#34;https://jonathanvacher.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonathan Vacher&lt;/a&gt; will present his recent work on &amp;ldquo;&lt;strong&gt;Unifying Different Psychometric Methods : Theory and Experiment&lt;/strong&gt;&amp;rdquo;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The two-alternative forced choice (2AFC) paradigm is one of the main methods used to measure perceptual thresholds and biases. Measurements from a 2AFC experiment can be modelled using signal detection theory (SDT) from which the psychometric function can be derived theoretically. Recent efforts to combine SDT with Bayesian probabilities has linked thresholds and biases to hypothesized prior knowledge and optimal encoding/decoding [1]. From another perspective, the maximum likelihood difference scaling (MLDS) paradigm is a more recent method that allows the experimenter to estimate a perceptual scale that links a physical property to a psychological dimension [2]. Such a perceptual scale is obtained from the comparison of relative differences between pairs of stimuli. Here again, the underlying model can be understood in terms of SDT and Bayesian probabilities. However, no comparison between MLDS and 2AFC measurements has been performed yet. Here, we introduce the theory that unifies those measurements and we present some preliminary experimental results. In this context, we further explore how MLDS measurements could help to understand the perception of more complex textures generated from the statistic of deep neural network features [3].&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;[1] Wei, X. X., &amp;amp; Stocker, A. A. (2017). Lawful relation between perceptual bias and discriminability. Proceedings of the National Academy of Sciences, 114(38), 10244-10249.&lt;/p&gt;
&lt;p&gt;[2] Maloney, L. T., &amp;amp; Yang, J. N. (2003). Maximum likelihood difference scaling. Journal of Vision, 3(8):5, 573-585.&lt;/p&gt;
&lt;p&gt;[3] Vacher, J. &amp;amp; Davila, A., Kohn, A. &amp;amp; Coen-Cagli, R. (2021). Texture Interpolation for Probing Visual Perception. Advances in Neural Information Processing Systems, 33.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Dr. &lt;a href=&#34;https://jonathanvacher.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonathan Vacher&lt;/a&gt; was a student at √âcole Normale Sup√©rieure de Cachan (now¬†&lt;a href=&#34;http://www.ens-paris-saclay.fr/en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Saclay&lt;/a&gt;) where he pursued a degree in mathematics and applied mathematics. He completed his bachelor&amp;rsquo;s and master&amp;rsquo;s degree with a specialty in computational imaging and machine learning (&lt;a href=&#34;http://math.ens-paris-saclay.fr/version-francaise/formations/master-mva/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Master MVA&lt;/a&gt;). He started a multidisciplinary PhD in mathematics (&lt;a href=&#34;http://www.dauphine.fr/en/research/research-centers/ceremade-umr-7534.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paris Dauphine University, CEREMADE)&lt;/a&gt;¬†and neuroscience (&lt;a href=&#34;https://neuropsi.cnrs.fr/fr/icn/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNRS, UNIC&lt;/a&gt;) under the supervision of¬†&lt;a href=&#34;http://www.gpeyre.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gabriel Peyr√©&lt;/a&gt;¬†and¬†&lt;a href=&#34;https://www.unic.cnrs-gif.fr/people/cyril_monier/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cyril Monier&lt;/a&gt;. Then, Jonathan was a postdoc at Albert Einstein College of Medicine in New-York between 2017 and 2020 while initiating a collaboration with Pascal Mamassian from the Laboratoire des Syst√®mes Perceptifs ()√âcole Normale Sup√©rieure de Paris) where he is currently a postdoc.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>2022-02-24 : CONECT Seminar - &#34;Explainable AI for computational auditory neurosciences&#34; (Etienne Thoret)</title>
      <link>https://conect-int.github.io/talk/2022-02-24-conect-seminar-explainable-ai-for-computational-auditory-neurosciences-etienne-thoret/</link>
      <pubDate>Thu, 24 Feb 2022 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2022-02-24-conect-seminar-explainable-ai-for-computational-auditory-neurosciences-etienne-thoret/</guid>
      <description>&lt;p&gt;Etienne Thoret (ILCB/PRISM/LIS/AMU) kindly accepted to present his research project during our novel series of CONECT-core ¬© seminars (=seminars open to all but focused on the core theoretical scientific questions of the CONECT members):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Explainable AI for computational auditory neurosciences&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Machine learning and deep neural networks have been raised as compelling models to simulate a broad range of tasks on signals: from classification of sound events to the prediction of human physiological state from electrophysiological data. But what do we really understand about these models and how do they process the information they have been trained to process? As users, we often use them as tools without precisely understanding their mechanistic and representational underpinnings. In this talk, I&amp;rsquo;ll present recent works on how we can take part of these computational systems to answer fundamental research mysteries on auditory perception, speech production and cerebral processing. Beyond acoustics and sound perception, these techniques can find applications for the modeling of a variety of systems, including computational vision in robotics, haptics and clinical applications.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>2021-12-10 : CONECT seminar - &#34;Sequence anticipation and STDP emerge from a voltage-based predictive learning rule&#34; (Matteo Saponati)</title>
      <link>https://conect-int.github.io/talk/2021-12-10-conect-seminar-sequence-anticipation-and-stdp-emerge-from-a-voltage-based-predictive-learning-rule-matteo-saponati/</link>
      <pubDate>Fri, 10 Dec 2021 11:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2021-12-10-conect-seminar-sequence-anticipation-and-stdp-emerge-from-a-voltage-based-predictive-learning-rule-matteo-saponati/</guid>
      <description>&lt;p&gt;During a seminar at the Institute of Neurosciences Timone in Marseille, &lt;a href=&#34;https://github.com/matteosaponati&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Matteo Saponati&lt;/a&gt;, will present his recent work showing that &amp;ldquo;&lt;strong&gt;Sequence anticipation and STDP emerge from a voltage-based predictive learning rule&lt;/strong&gt;&amp;rdquo;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Intelligent behavior depends on the brain‚Äôs ability to anticipate future events. However, the learning rules that enable neurons to predict and fire ahead of sensory inputs remain largely unknown. We propose a plasticity rule based on predictive processing, where the neuron learns a low-rank model of the synaptic input dynamics in its membrane potential. Neurons thereby amplify those synapses that maximally predict other synaptic inputs based on their temporal relations, which provide a solution to an optimization problem that can be implemented at the single-neuron level using only local information. Consequently, neurons learn sequences over long timescales and shift their spikes towards the first inputs in a sequence. We show that this mechanism can explain the development of anticipatory motion signaling and recall in the visual system. Furthermore, we demonstrate that the learning rule gives rise to several experimentally observed STDP (spike-timing-dependent plasticity) mechanisms. These findings suggest prediction as a guiding principle to orchestrate learning and synaptic plasticity in single neurons.
&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.10.31.466667v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.biorxiv.org/content/10.1101/2021.10.31.466667v1&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;when: Friday 10th of December at 11am&lt;/li&gt;
&lt;li&gt;where: Salle Laurent Vinay at the &lt;a href=&#34;https://www.int.univ-amu.fr/contact&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Institute of Neurosciences Timone&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;a href=&#34;https://github.com/matteosaponati&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Matteo Saponati&lt;/a&gt; is a PhD candidate at &lt;a href=&#34;https://www.esi-frankfurt.de/research/vinck-lab/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ernst Str√ºngmann Institute (ESI) for Neuroscience - IMPRS for Neural Circuits&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>2021-06-17: CONECT meeting #3</title>
      <link>https://conect-int.github.io/talk/2021-06-17-conect-meeting-#3/</link>
      <pubDate>Thu, 17 Jun 2021 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2021-06-17-conect-meeting-#3/</guid>
      <description>&lt;p&gt;There will be a third meeting of the CONECT group for the Thursday meeting devoted to the kick-off of these initiatives for INT3. It will consist of an internal meeting (14:00-15:00) and of a talk open to the institute (15:00-16:00).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2021-05-27: CONECT meeting - talk by Matthias Pessiglione</title>
      <link>https://conect-int.github.io/talk/2021-05-27-conect-meeting-talk-by-matthias-pessiglione/</link>
      <pubDate>Thu, 27 May 2021 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2021-05-27-conect-meeting-talk-by-matthias-pessiglione/</guid>
      <description>&lt;p&gt;This is the second meeting of the CONECT group for the Thursday meeting devoted to the kick-off of these initiatives for INT3. It consists of an internal meeting (14:00-15:00) and of a talk open to the institute (15:00-16:00) by &lt;a href=&#34;https://insb.cnrs.fr/fr/personne/mathias-pessiglione&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Matthias Pessiglione (INSB)&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;14:00 - 15:00  coordination on scientific perimeter &amp;amp; objectives&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;15:00 - 16:00 - scientific presentation by &lt;a href=&#34;https://insb.cnrs.fr/fr/personne/mathias-pessiglione&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Matthias Pessiglione (INSB)&lt;/a&gt; on his recent work :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;&amp;ldquo;Computational approach to motivational disorders&amp;rdquo;&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;a preview in this paper : &lt;a href=&#34;https://academic.oup.com/brain/article/141/3/629/4675073&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Why not try harder? Computational approach to motivation deficits in neuro-psychiatric diseases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;of related interest &lt;a href=&#34;https://www.odilejacob.fr/catalogue/sciences/neurosciences/vacances-de-momo-sapiens_9782738151742.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Les Vacances de Momo Sapiens &lt;/a&gt; (see the &lt;a href=&#34;https://www.lemonde.fr/sciences/article/2021/05/25/nos-comportements-automatiques-constitutent-l-essentiel-de-nos-actions_6081429_1650684.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Le Monde interview on that book&lt;/a&gt; )&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Zoom link  &lt;a href=&#34;https://univ-amu-fr.zoom.us/j/91200617032?pwd=WHRWNy9kNXoyQWZhUHMzS0RzSW1udz09&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://univ-amu-fr.zoom.us/j/91200617032?pwd=WHRWNy9kNXoyQWZhUHMzS0RzSW1udz09&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>2021-04-29: CONECT kick-off - talk by Rufin van Rullen</title>
      <link>https://conect-int.github.io/talk/2021-04-29-conect-kick-off-talk-by-rufin-van-rullen/</link>
      <pubDate>Thu, 29 Apr 2021 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2021-04-29-conect-kick-off-talk-by-rufin-van-rullen/</guid>
      <description>&lt;p&gt;First meeting of the CONECT group for the Thursday meeting devoted to the kick-off of these initiatives for INT3. It consists of an internal meeting (14:00-15:00) and of a talk open to the institute (15:00-16:00).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;14:00 - 15:00  coordination on scientific perimeter &amp;amp; objectives&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;presentation of the working document / round table to discuss these points&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;means of action / operationalization :&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Master 2 scholarship (call for topics / we arrive with proposals + application, then selection jury) - possibility of a 3 months extension to arrive at 9 months&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;forecast student training day - 2022&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;15:00 - 15:30 - pause / caf√©&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;15:30 - 16:30 - scientific presentation by &lt;a href=&#34;http://cerco.cnrs.fr/pagesp/rufin/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rufin van Rullen&lt;/a&gt; on his recent work :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;R VanRullen, A Alamia&lt;/em&gt; &lt;a href=&#34;https://arxiv.org/abs/2104.05575&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GAttANet: Global attention agreement for convolutional neural networks&lt;/a&gt; - arXiv preprint arXiv:2104.05575, 2021&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>2021-04-23 : PhDProgram course in computational neuroscience</title>
      <link>https://conect-int.github.io/talk/2021-04-23-phdprogram-course-in-computational-neuroscience/</link>
      <pubDate>Fri, 23 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2021-04-23-phdprogram-course-in-computational-neuroscience/</guid>
      <description>&lt;p&gt;Computational neuroscience is an expanding field that is proving to be essential in neurosciences. The aim of this short intensive course will be to provide a common background in computational neuroscience. The course, after a brief historical overview of the field, will focus on the description of a few selected modelling and theoretical approaches that are currently developed, including details about their limits and advantages, and that can be applied to different scales of analysis (from the single neuron to the whole brain). In addition, we will provide a theoretical and a practical session on artificial neuronal networks of spiking neurons.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Objectives: 	Understanding how computational modelling can be used to formulate and solve neuroscience problems at different spatial and temporal scales; learning the formal notions of information, encoding and decoding and experimenting their use on specific examples&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Where: Marseille (France)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What: &lt;a href=&#34;https://ametice.univ-amu.fr/course/view.php?id=72868&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Session #3 : Realistic spiking neural networks&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Computational Neuroscience Tutorial&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Friday, April 23, 2021; 9:00-12:30&lt;/li&gt;
&lt;li&gt;Objective: Applying the Theory on the eBrains platform&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/albertoarturovergani/CNT-2021&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/albertoarturovergani/CNT-2021&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;em&gt;Hands-on practice&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Friday, April 23, 2021; 14:00-17:00&lt;/li&gt;
&lt;li&gt;Objective: replicating Mainen &amp;amp; Sejnowski (1995)&lt;/li&gt;
&lt;li&gt;github : &lt;a href=&#34;https://github.com/CONECT-INT/2021-04-23_PhDProgram-course-in-computational-neurosciences/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/CONECT-INT/2021-04-23_PhDProgram-course-in-computational-neurosciences/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;AMETICE :  &lt;a href=&#34;https://ametice.univ-amu.fr/course/view.php?id=72868#section-4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://ametice.univ-amu.fr/course/view.php?id=72868#section-4&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!--more--&gt;
&lt;h1 id=&#34;hands-on-session-reproduction-of-the-article-by-mainen--sejnowski-1995&#34;&gt;Hands-on session: reproduction of the article by Mainen &amp;amp; Sejnowski, 1995&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The aim of this task is to read a scientific article, to reproduce it with simulations of a neuron and to improve the understanding of the study.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Modalities: students will organize themselves alone, in pairs or in triads to provide a brief in the form of a &lt;a href=&#34;https://jupyter.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;notebook&lt;/a&gt; completed from &lt;a href=&#34;https://raw.githubusercontent.com/CONECT-INT/2021-04_PhDProgram-neurosciences-computationnelles/master/MainenSejnowski1995.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the model that is provided&lt;/a&gt;. Follow the &lt;code&gt;QUESTION&lt;/code&gt; tags in the notebook to guide you in this writing. Comments should be made in the notebook (don&amp;rsquo;t forget to save your changes).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tools needed: &lt;a href=&#34;https://jupyter.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jupyter&lt;/a&gt;, with &lt;a href=&#34;https://numpy.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;numpy&lt;/a&gt; and &lt;a href=&#34;https://matplotlib.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;matplotlib&lt;/a&gt;. These are standard tools and are easily installed on any platform. Other hosted solutions exist:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.ebrains.eu/bin/view/Collabs/neuromorphic/SpiNNaker/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ebrains / HBP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://deepnote.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://deepnote.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;on &lt;a href=&#34;https://colab.research.google.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GoogleColab&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/CONECT-INT/2021-04_PhDProgram-neurosciences-computationnelles/blob/master/MainenSejnowski1995.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://colab.research.google.com/github/CONECT-INT/2021-04_PhDProgram-neurosciences-computationnelles/blob/master/MainenSejnowski1995.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;context&#34;&gt;context&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The goal of this first task is to create a &amp;ldquo;raster plot&amp;rdquo; that shows the reproducibility of a spike train with repetitions of the same stimulus, as in this work in the &lt;a href=&#34;https://laurentperrinet.github.io/2019-04-03_a_course_on_vision_and_modelization/#/1/3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;rodent retina&lt;/a&gt; or in the &lt;a href=&#34;https://laurentperrinet.github.io/2019-04-03_a_course_on_vision_and_modelization/#/1/6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cat cortex (V1)&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here, we will attempt to replicate Figure 1 of &lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.299.8560&amp;amp;rep=rep1&amp;amp;type=pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mainen &amp;amp; Sejnowski (1995)&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-figure-1&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://i.stack.imgur.com/ixnrz.png&#34; alt=&#34;Mainen Sejnowski 1995&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      figure 1
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;getting-to-know-the-tools-numpy-and-matplotlib&#34;&gt;getting to know the tools: numpy and matplotlib&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;we are going to create vectors representing the dynamics of a value as a function of time&lt;/li&gt;
&lt;li&gt;for that, we create a vector `time&amp;rsquo; representing 1 second with a precision of dt=.5ms&lt;/li&gt;
&lt;li&gt;in a first step, we will create a plot of a spike, a slot &amp;amp; a sinusoid&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;problem-definition-leaky-integrate-and-fire-neuron&#34;&gt;problem definition: leaky-integrate and fire neuron&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;we will simulate 1 neuron for 2 seconds with a precision of dt=1ms&lt;/li&gt;
&lt;li&gt;for that, we use the equation of a leaky-IF&lt;/li&gt;
&lt;li&gt;then we show its response to the stimuli created above&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;injection-of-a-noise&#34;&gt;injection of a noise&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;As in figure 1 of Mainen &amp;amp; Sejnowski (1995), we add a noise to the current injection&lt;/li&gt;
&lt;li&gt;this noise can be characterized by its amplitude and its characteristic time: what is the impact on the result?&lt;/li&gt;
&lt;li&gt;what happens when we include an internal noise to the dynamics of the neuron?&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;appendices&#34;&gt;Appendices&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;an article to read about time in the brain: &lt;a href=&#34;https://laurentperrinet.github.io/publication/perrinet-19-temps/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/publication/perrinet-19-temps/&lt;/a&gt; &lt;a href=&#34;https://theconversation.com/temps-et-cerveau-comment-notre-perception-nous-fait-voyager-dans-le-temps-127567&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;direct link&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://laurentperrinet.github.io/talk/2019-04-18-jnlf/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;From illusions to visual hallucinations: a door on perception&lt;/a&gt; - (&lt;a href=&#34;https://laurentperrinet.github.io/2019-04-18_JNLF/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;slides&lt;/a&gt;) - article on visual perception: &lt;a href=&#34;https://laurentperrinet.github.io/post/2019-06-06-theconversation/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/post/2019-06-06-theconversation/&lt;/a&gt; &lt;a href=&#34;https://theconversation.com/illusions-et-hallucinations-visuelles-une-porte-sur-la-perception-117389&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;direct link&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://laurentperrinet.github.io/talk/2019-04-03-a-course-on-vision-and-modelization/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Modelling spiking neural networks using Brian, Nest and pyNN&lt;/a&gt; - (&lt;a href=&#34;https://laurentperrinet.github.io/2019-01-14_LACONEU/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;slides&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://laurentperrinet.github.io/talk/2018-03-26-cours-neuro-comp-fep/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tutorial on predictive coding&lt;/a&gt; &lt;a href=&#34;https://laurentperrinet.github.io/talk/2017-06-30-telluride/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/talk/2017-06-30-telluride/&lt;/a&gt; &lt;a href=&#34;https://laurentperrinet.github.io/sciblog/files/2017-06-30_Telluride.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://laurentperrinet.github.io/sciblog/files/2017-06-30_Telluride.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>2020-09-11 : CONECT seminar - &#34;Feedforward and feedback processes in visual recognition&#34; (T Serre)</title>
      <link>https://conect-int.github.io/talk/2020-09-11-conect-seminar-feedforward-and-feedback-processes-in-visual-recognition-t-serre/</link>
      <pubDate>Fri, 11 Sep 2020 14:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/talk/2020-09-11-conect-seminar-feedforward-and-feedback-processes-in-visual-recognition-t-serre/</guid>
      <description>&lt;p&gt;During a seminar at the Institute of Neurosciences Timone in Marseille, &lt;a href=&#34;http://serre-lab.clps.brown.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Thomas Serre&lt;/a&gt; will present his recent work on &amp;ldquo;Feedforward and feedback processes in visual recognition&amp;rdquo;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Progress in deep learning has spawned great successes in many engineering applications. As a prime example, convolutional neural networks, a type of feedforward neural networks, are now approaching ‚Äì and sometimes even surpassing ‚Äì human accuracy on a variety of visual recognition tasks. In this talk, however, I will show that these neural networks and their recent extensions exhibit a limited ability to solve seemingly simple visual reasoning problems involving incremental grouping, similarity, and spatial relation judgments. Our group has developed a recurrent network model of classical and extra-classical receptive fields that is constrained by the anatomy and physiology of the visual cortex. The model was shown to account for diverse visual illusions providing computational evidence for a novel canonical circuit that is shared across visual modalities. I will show that this computational neuroscience model can be turned into a modern end-to-end trainable deep recurrent network architecture that addresses some of the shortcomings exhibited by state-of-the-art feedforward networks for solving complex visual reasoning tasks. This suggests that neuroscience may contribute powerful new ideas and approaches to computer science and artificial intelligence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Dr. &lt;a href=&#34;http://serre-lab.clps.brown.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Thomas Serre&lt;/a&gt; is an Associate Professor in Cognitive Linguistic &amp;amp; Psychological Sciences and an affiliate of the Carney Institute for Brain Science at Brown University. He received a Ph.D. in Neuroscience from MIT in 2006 and an MSc in EECS from T√©l√©com Bretagne (France) in 2000. His research seeks to understand the neural computations supporting visual perception and has been featured in the BBC series ‚ÄúVisions from the Future‚Äù and other news articles (The Economist, New Scientist, Scientific American, IEEE Computing in Science and Technology, Technology Review and Slashdot). Dr. Serre is the Faculty Director of the Center for Computation and Visualization and the Associate Director of the Initiative for Computation in Brain and Mind at Brown University. He also holds an International Chair in AI within the Artificial and Natural Intelligence Toulouse Institute (France). Dr. Serre has served as an area chair and a senior program committee member for top-tier machine learning and computer vision conferences including AAAI, CVPR, and NeurIPS. He is currently serving as a domain expert for IARPA‚Äôs Machine Intelligence from Cortical Networks (MICrONS) program and as a scientific advisor for Vium, Inc. He was the recipient of an NSF Early Career Award as well as DARPA‚Äôs Young Faculty Award and Director‚Äôs Award.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An example preprint / working paper</title>
      <link>https://conect-int.github.io/publication/preprint/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/publication/preprint/</guid>
      <description>&lt;p&gt;toto
Supplementary notes can be added here, including &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://conect-int.github.io/slides/conect/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/slides/conect/</guid>
      <description>
&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/open-book.jpg&#34;
  &gt;

&lt;h1 id=&#34;conect&#34;&gt;CoNeCt&lt;/h1&gt;
&lt;h2 id=&#34;the-computational-neuroscience-center--int&#34;&gt;the &lt;strong&gt;Co&lt;/strong&gt;mputational &lt;strong&gt;Ne&lt;/strong&gt;uroscience &lt;strong&gt;C&lt;/strong&gt;en&lt;strong&gt;t&lt;/strong&gt;er @ INT&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://conect-int.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://conect-int.github.io&lt;/a&gt;&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;CONECT with one N&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;tremendous-technological-advances&#34;&gt;Tremendous technological advances&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;two photon imaging&lt;/li&gt;
&lt;li&gt;large population recording-array technologies&lt;/li&gt;
&lt;li&gt;optogenetic circuit control tools&lt;/li&gt;
&lt;li&gt;transgenic manipulations&lt;/li&gt;
&lt;li&gt;large volume circuit reconstructions&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;p&gt;Tremendous technological advances over the past decade&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;These experiments have begun to produce a huge amount of data, on a broad spectrum of temporal and spatial scales,&lt;/li&gt;
&lt;li&gt;providing finer and more quantitative descriptions of the biological reality than we would have been able to dream of only a decade ago.&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;a-transdisciplinary-revolution&#34;&gt;A transdisciplinary revolution&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;across several disciplines (physics, genetics, biology, robotics, psychiatry, ..)&lt;/li&gt;
&lt;li&gt;and multiple scales (from micro to macro, from short to long-term, from theory to biology)&lt;/li&gt;
&lt;li&gt;new frontiers&lt;span class=&#34;fragment &#34; &gt;
‚Ä¶ and new challenges
&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;daunting complexity of the biological reality revealed by these technologies highlights the importance of neurophysics&lt;/li&gt;
&lt;li&gt;to provide a conceptual bridge between abstract principles of brain function and their biological implementations within neural circuits.&lt;/li&gt;
&lt;li&gt;This revolution is accompanied by a parallel revolution in the domain of Artificial Intelligence. An exponential number of algorithms in sensory processing, such as image classification, or reinforcement learning have realized practical tools which have replaced the classical tools we were using on a daily basis by a novel range of intelligent tools of a new generation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;This is the context in which we are creating CONECT.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;conect-computational-neuroscience-center&#34;&gt;CoNeCt: &lt;strong&gt;Co&lt;/strong&gt;mputational &lt;strong&gt;Ne&lt;/strong&gt;uroscience &lt;strong&gt;C&lt;/strong&gt;en&lt;strong&gt;t&lt;/strong&gt;er&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;close collaboration between experimentalists and theoreticians&lt;/li&gt;
&lt;li&gt;share state-of-the-art (experimentalists well aware of theoretical approaches, experimental techniques for theoreticians)&lt;/li&gt;
&lt;li&gt;complementary in its purpose from neuroinformatics&amp;hellip; &lt;span class=&#34;fragment &#34; &gt;
but distinct
&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;We are convinced that close collaboration between experimentalists and theoreticians in neuroscience is essential to develop mechanistic as well as quantitative understandings of how the brain performs its functions. This is in fact a primary motivating force in establishing this center.&lt;/li&gt;
&lt;li&gt;However, for such collaborations to be effective, experimentalists must be well aware of the approaches and challenges in modeling while theoreticians must be well acquainted with the experimental techniques, their power and the challenges they present.&lt;/li&gt;
&lt;li&gt;CoNeCt has also the ambition to contribute to the training of a new generation of neuroscientists who will have all these qualities.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This approach is therefore complementary but distinct in its purpose from neuroinformatics (creation of tools for analyzing neuroscientific data) or artificial intelligence (creation of algorithms inspired by the functioning of the brain). The field of computational neuroscience is still young but its community is now structured in an autonomous community with strong interaction with the other branches of neuroscience. It is this autonomy that we want to foster at INT.
&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;objectives-of-conect&#34;&gt;Objectives of CoNeCt&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;to create a space for scientific discussion and animation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;train students and staff and attract young researchers:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;structuring the network of computational neurosciences at INT, on Timone, on AMU and in France &amp;amp; International&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;lots of work - bottom approach so far&lt;/li&gt;
&lt;li&gt;no action taken&lt;/li&gt;
&lt;li&gt;lots of work - existence of top-down initiatives&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;actions-of-conect&#34;&gt;Actions of CoNeCt&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;










  









  




&lt;div class=&#34;view-list view-list-item&#34;&gt;
  &lt;i class=&#34;far fa-newspaper pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
  &lt;a href=&#34;https://conect-int.github.io/post/actors-conect/&#34; &gt;Actors of CONECT&lt;/a&gt;

  

  

  

&lt;/div&gt;



&lt;/li&gt;
&lt;li&gt;










  









  




&lt;div class=&#34;view-list view-list-item&#34;&gt;
  &lt;i class=&#34;far fa-newspaper pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
  &lt;a href=&#34;https://conect-int.github.io/post/objectives-conect/&#34; &gt;Objectives of CONECT&lt;/a&gt;

  

  

  

&lt;/div&gt;



&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://conect-int.github.io/event&#34;&gt;Past events&lt;/a&gt; and future&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://amubox.univ-amu.fr/f/867023067&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Methodology&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Actors&lt;/li&gt;
&lt;li&gt;we already organized events within or outside INT&lt;/li&gt;
&lt;li&gt;objectives : exist&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://conect-int.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://conect-int.github.io&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;mailto://int-conect@univ-amu.fr&#34;&gt;Contact us @ int-conect@univ-amu.fr!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://framateam.org/int-marseille/channels/conect&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Let&amp;rsquo;s discuss on Mattermost&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://conect-int.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Eating...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
  One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  Three
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Only the speaker can read these notes
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Press &lt;span class=&#34;sb&#34;&gt;`S`&lt;/span&gt; key to view
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {{% /speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/media/boards.jpg&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;#0000FF&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;my-style&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-css&#34; data-lang=&#34;css&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h3&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;navy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example journal article</title>
      <link>https://conect-int.github.io/publication/journal-article/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/publication/journal-article/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>https://conect-int.github.io/publication/conference-paper/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/publication/conference-paper/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://conect-int.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://conect-int.github.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://conect-int.github.io/people/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://conect-int.github.io/people/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
