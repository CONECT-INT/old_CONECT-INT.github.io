[{"authors":["alberto-vergani"],"categories":null,"content":"Project description: Visual computations using Spatio-temporal Diffusion Kernels and Traveling Waves Biological vision is surprisingly efficient. To take advantage of this efficiency, Deep learning and convolutional neural networks (CNNs) have recently produced great advances in artificial computer vision. However, these algorithms now face multiple challenges: learned architectures are often not interpretable, disproportionally energy greedy, and often lack the integration of contextual information that seems optimized in biological vision and human perception. It is clear from recent advances in system and computational neuroscience that nonlinear, recurrent interactions in visual cortical networks are key to this efficiency (Tang et al., 2018; Kietzmann et al., 2019). We will use inspiration from neurophysiology and brain imaging to resolve this apparent gap between traditional CNNs and biological visual systems.\nIn this post-doctoral project, I will address these major limitations by focusing on specific dynamical features of cortical circuits: lateral diffusion of sensory-evoked traveling waves (Chavane et al., 2011; Muller et al., 2018) and dynamic neuronal association fields (Frégnac et al., 2012; Frégnac et al., 2016; Gerard-Mercier et al., 2016). Indeed, the architecture of primary visual cortex (V1), the direct target of the feedforward visual flow, contains dense local recurrent connectivity with sparse long-range connections (Voges and Perrinet, 2012). Such connections add to the traditional convolutional kernels representing feedforward and local recurrent amplification a novel lateral interaction kernel within a single layer (across positions and channels). Less studied, but probably decisive in active vision, recurrent cortico-cortical loops add a level of distributed top-down complexity which participates to the lateral integration of sensory input and perceptual context (Keller et al., 2019). Coupled with the continuous time dynamics of cortical circuits, this elaborate multiplexed architecture provides the conditions possible for generating information diffusion through traveling waves. Inspired by recent work in neuroscience uncovering the ubiquity of these waves during visual processing, we aim to design a self-supervised CNN that will exploit these dynamics for new applications in computer vision.\nThe proposed work will be organized as a collaboration between two labs (INT, Marseille and UNIC, Gif) along three tasks to be integrated in a unified model:\n  The starting point will be to extend results of self-supervised learning that we have obtained on static, natural images (Boutin et al., 2019) showing in a recurrent cortical-like artificial CNN architecture the emergence of interactions which phenomenologically correspond to the \u0026ldquo;association field\u0026rdquo; described at the psychophysical (Field et al., 1993), spiking (Li and Gilbert, 2002) and synaptic (Gerard-Mercier et al., 2016) levels.\n  The central aim will be to develop a dynamical version of this feedback/lateral kernel in the context of the ANR Horizontal-V1 project, linking the two labs and confronted to their recent electrophysiological data pointing to different classes of spatio-temporal diffusion and different degree of anisotropies during apparent and continuous motion.\n  The implementation of this kernel inspired by CNN theory will be compared with a biologically realistic models of the early visual system (Antolik et al., 2019), and simulations of the lateral diffusion kernel will be developed in collaboration with Jan Antolik, external collaborator to the ANR grant. In parallel, using tools linking neural activity to VSD imaging (Muller et al., 2014; Chemla et al., 2019), we will analyze at a more mesocopic level the role of observed traveling waves in forming efficient representations of the visual world.\n  Research context This project is funded by the French National Research Agency (ANR) under the ANR Horizontal V1 grant (coordinator Y. Frégnac) which aims at understanding the emergence of sensory predictions linking local shape attributes (orientation, contour) to global indices of movement (direction, speed, trajectory) at the earliest stage of cortical processing (primary visual cortex, i.e. V1). The cross-talk between physiological and theoretical approaches is fostered by the close collaboration with the teams of Frédéric Chavane at INT and Yves Frégnac at UNIC. The theoretical work is performed in close collaboration with Lyle Muller (Western U) and Jan Antolik (Prague). This project is primarily hosted at the Institut de Neurosciences de la Timone.\nReferences   Antolik, J, C Monier, Y Frégnac, AP Davison. (2019).  \u0026ldquo;A comprehensive data-driven model of cat primary visual cortex.\u0026rdquo; BioRxiv, 416156.\n  Boutin, Victor, Angelo Franciosini, Frédéric Chavane, Franck Ruffier, and Laurent U Perrinet. (2019).  \u0026ldquo;Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system.\u0026rdquo; arXiv\n  Chavane, F., C. Monier, V. Bringuier, P. Baudot, L. Borg-Graham, J. Lorenceau, and Y. Frégnac. 2000.  \u0026ldquo;The Visual Cortical Association Field: A Gestalt Concept or a Psychophysiological Entity?\u0026rdquo; Frontiers in System Neuroscience 4(5): 1-26.\n  Chavane, F., Sharon, D., Jancke, D., Marre, O., Frégnac, Y. and Grinvald, A. (2011).  \u0026ldquo;Lateral spread of orientation selectivity in V1 is controlled by intracortical cooperativity.\u0026rdquo; Journal of Physiology Paris 94 (5-6): 333\u0026ndash;42.\n  Chemla, Sandrine, Alexandre Reynaud, Matteo diVolo, Yann Zerlaut, Laurent Perrinet, Alain Destexhe, and Frédéric Chavane.  (2018). \u0026ldquo;Suppressive Waves Disambiguate the Representation of Long-Range Apparent Motion in Awake Monkey V1.\u0026rdquo; Journal of Neuroscience 39 (22) 4282-4298.\n  Field, D.J., Hayes, A. and Hess, R.F. (1993).  \u0026ldquo;Contour integration by the human visual system: Evidence for a local “association field”.\u0026rdquo; Vision Research 33 (2), pp. 173-193.\n  Frégnac, Y. (2012)  \u0026ldquo;Reading out the synaptic echoes of low-level perception in V1.\u0026rdquo; European Conference in Computer Vision 486-495. Springer, Berlin, Heidelberg.\n  Frégnac, Y., Fournier, J., Gerard-Mercier, F., Monier, C., Carelli, P., , M., Troncoso, X. (2016).  \u0026ldquo;The Visual Brain: Computing Through Multiscale Complexity.\u0026rdquo; In Micro-, Meso- and Macro-Dynamics of the Brain pp 43-57.\n  Gerard-Mercier, Florian, Pedro V Carelli, Marc Pananceau, Xoana G Troncoso, and Yves Frégnac. (2016).  \u0026ldquo;Synaptic Correlates of Low-Level Perception in V1.\u0026rdquo; Journal of Neuroscience 36 (14): 3925\u0026ndash;42.\n  Keller, A., Roth, M.M. and Scanziani, M. (2019).  2019. \u0026ldquo;The feedback receptive field of neurons in the mammalian primary visual cortex.\u0026rdquo; American Society for Neuroscience Abstracts, 403.13. Chicago.\n  Kietzmann, Tim C., Courtney J. Spoerer, Lynn K. A. Sörensen, Radoslaw M. Cichy, Olaf Hauk, and Nikolaus Kriegeskorte.  (2019). \u0026ldquo;Recurrence Is Required to Capture the Representational Dynamics of the Human Visual System.\u0026rdquo; Proceedings of the National Academy of Sciences, October, 201905544.\n  Li W, Piëch V, Gilbert CD (2006). \u0026ldquo;Contour saliency in primary visual cortex.\u0026rdquo; Neuron, 50(6):951–962.\n  Muller, Lyle, Alexandre Reynaud, Frédéric Chavane, and Alain Destexhe.  (2014). \u0026ldquo;The Stimulus-Evoked Population Response in Visual Cortex of Awake Monkey Is a Propagating Wave.\u0026rdquo; Nature Communications 5: 3675.\n  Muller, Lyle, Frédéric Chavane, John Reynolds, and Terrence J Sejnowski.  (2018). \u0026ldquo;Cortical Travelling Waves: Mechanisms and Computational Principles.\u0026rdquo; Nature Reviews Neuroscience 19 (5): 255.\n  Tang, Hanlin, Martin Schrimpf, William Lotter, Charlotte Moerman, Ana Paredes, Josue Ortega Caro, Walter Hardesty, David Cox, and Gabriel Kreiman.  (2018). \u0026ldquo;Recurrent computations for visual pattern completion.\u0026rdquo; Proceedings of the National Academy of Sciences 115 (35) 8835-8840.\n  Voges, Nicole, and Laurent U Perrinet. (2012). \u0026ldquo;Complex Dynamics in Recurrent Cortical Networks Based on Spatially Realistic Connectivities.\u0026rdquo; Frontiers in Computational Neuroscience 6.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1619086105,"objectID":"ffd0421ebbcd6a9694092807965ab7a5","permalink":"https://CONECT-INT.github.io/author/alberto-arturo-vergani/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/alberto-arturo-vergani/","section":"authors","summary":"Project description: Visual computations using Spatio-temporal Diffusion Kernels and Traveling Waves Biological vision is surprisingly efficient. To take advantage of this efficiency, Deep learning and convolutional neural networks (CNNs) have recently produced great advances in artificial computer vision.","tags":["phd-icn"],"title":"Alberto Arturo Vergani","type":"authors"},{"authors":["anna-montagnini"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1619086105,"objectID":"45d66edaf2e796c6cc66249755f036b9","permalink":"https://CONECT-INT.github.io/author/anna-montagnini/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/anna-montagnini/","section":"authors","summary":"","tags":null,"title":"Anna Montagnini","type":"authors"},{"authors":["david-hansel"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1619094007,"objectID":"cca39b7dabd5880271fac7809eab8503","permalink":"https://CONECT-INT.github.io/author/david-hansel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/david-hansel/","section":"authors","summary":"","tags":null,"title":"David Hansel","type":"authors"},{"authors":["emmanuel-dauce"],"categories":null,"content":"Emmanuel Daucé is associate professor at the Ecole Centrale de Marseille, doing his research in Computational Neuroscience at the Institut de Neurosciences de la Timone (France), a joint research unit (CNRS / Aix-Marseille Université). His research lies at the crossroad of machine learning, artificial intelligence and neuroscience, seeking to develop innovative computational models and methods though remaining consistent with the principles of biological systems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1619086105,"objectID":"fc438c70df365b40938335cb7e325000","permalink":"https://CONECT-INT.github.io/author/emmanuel-dauce/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/emmanuel-dauce/","section":"authors","summary":"Emmanuel Daucé is associate professor at the Ecole Centrale de Marseille, doing his research in Computational Neuroscience at the Institut de Neurosciences de la Timone (France), a joint research unit (CNRS / Aix-Marseille Université).","tags":null,"title":"Emmanuel Daucé","type":"authors"},{"authors":["frederic-y-chavane"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1619086105,"objectID":"79ef82413d16cf2e1a5766e01762cafa","permalink":"https://CONECT-INT.github.io/author/frederic-chavane/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/frederic-chavane/","section":"authors","summary":"","tags":null,"title":"Frédéric Chavane","type":"authors"},{"authors":["laurent-u-perrinet"],"categories":null,"content":"Laurent Perrinet is a computational neuroscientist specialized in large scale neural network models of low-level vision, perception and action, currently at the \u0026ldquo;Institut de Neurosciences de la Timone\u0026rdquo; (France), a joint research unit (CNRS / Aix-Marseille Université). He co-authored more than 40 articles in computational neuroscience and computer vision. He graduated from the aeronautics engineering school SUPAERO, in Toulouse (France) with a signal processing and applied mathematics degree. He received a PhD in Cognitive Science in 2003 on the mathematical analysis of temporal spike coding of images by using a multi-scale and adaptive representation of natural scenes. His research program is focusing in bridging the complex dynamics of realistic, large-scale models of spiking neurons with functional models of low-level vision. In particular, as part of the FACETS and BrainScaleS consortia, he has developed experimental protocols in collaboration with neurophysiologists to characterize the response of population of neurons. Recently, he extended models of visual processing in the framework of predictive processing in collaboration with the team of Karl Friston at the University College of London. This method aims at characterizing the processing of dynamical flow of information as an active inference process. His current challenge within the NeOpTo team is to translate, or compile in computer terminology, this mathematical formalism with the event-based nature of neural information with the aim of pushing forward the frontiers of Artificial Intelligence systems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1619086105,"objectID":"34290dc2ee08b914b9858e658a955aa2","permalink":"https://CONECT-INT.github.io/author/laurent-u-perrinet/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/laurent-u-perrinet/","section":"authors","summary":"Laurent Perrinet is a computational neuroscientist specialized in large scale neural network models of low-level vision, perception and action, currently at the \u0026ldquo;Institut de Neurosciences de la Timone\u0026rdquo; (France), a joint research unit (CNRS / Aix-Marseille Université).","tags":null,"title":"Laurent U Perrinet","type":"authors"},{"authors":null,"categories":null,"content":"First meeting of the CONECT group for the Thursday meeting devoted to the kick-off of these initiatives for INT3. It consists of an internal meeting (14:00-15:00) and of a talk open to the institute (15:00-16:00).\n  14:00 - 15:00 coordination on scientific perimeter \u0026amp; objectives\n  presentation of the working document / round table to discuss these points\n  means of action / operationalization :\n  Master 2 scholarship (call for topics / we arrive with proposals + application, then selection jury) - possibility of a 3 months extension to arrive at 9 months\n  forecast student training day - 2022\n  15:00 - 15:30 - pause / café\n  15:30 - 16:30 - scientific presentation by Rufin van Rullen on his recent work :\n R VanRullen, A Alamia GAttANet: Global attention agreement for convolutional neural networks - arXiv preprint arXiv:2104.05575, 2021   ","date":1619704800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622104192,"objectID":"abbd0120b60ec65261994c06c40a6219","permalink":"https://CONECT-INT.github.io/event/2021-04-29-conect-kickoff/","publishdate":"2021-04-29T14:00:00Z","relpermalink":"/event/2021-04-29-conect-kickoff/","section":"event","summary":"First meeting of the CONECT group for the Thursday meeting devoted to the kick-off of these initiatives for INT3. It consists of an internal meeting (14:00-15:00) and of a talk open to the institute (15:00-16:00).\n","tags":null,"title":"2021-04-29: CONECT kick-off - talk by Rufin van Rullen","type":"event"},{"authors":null,"categories":null,"content":"Computational neuroscience is an expanding field that is proving to be essential in neurosciences. The aim of this short intensive course will be to provide a common background in computational neuroscience. The course, after a brief historical overview of the field, will focus on the description of a few selected modelling and theoretical approaches that are currently developed, including details about their limits and advantages, and that can be applied to different scales of analysis (from the single neuron to the whole brain). In addition, we will provide a theoretical and a practical session on artificial neuronal networks of spiking neurons.\n  Objectives: Understanding how computational modelling can be used to formulate and solve neuroscience problems at different spatial and temporal scales; learning the formal notions of information, encoding and decoding and experimenting their use on specific examples\n  Where: Marseille (France)\n  What: Session #3 : Realistic spiking neural networks\n   Computational Neuroscience Tutorial   Friday, April 23, 2021; 9:00-12:30 Objective: Applying the Theory on the eBrains platform https://github.com/albertoarturovergani/CNT-2021  Hands-on practice   Friday, April 23, 2021; 14:00-17:00 Objective: replicating Mainen \u0026amp; Sejnowski (1995) github : https://github.com/CONECT-INT/2021-04-23_PhDProgram-course-in-computational-neurosciences/ AMETICE : https://ametice.univ-amu.fr/course/view.php?id=72868#section-4   Hands-on session: reproduction of the article by Mainen \u0026amp; Sejnowski, 1995   The aim of this task is to read a scientific article, to reproduce it with simulations of a neuron and to improve the understanding of the study.\n  Modalities: students will organize themselves alone, in pairs or in triads to provide a brief in the form of a notebook completed from the model that is provided. Follow the QUESTION tags in the notebook to guide you in this writing. Comments should be made in the notebook (don\u0026rsquo;t forget to save your changes).\n  Tools needed: Jupyter, with numpy and matplotlib. These are standard tools and are easily installed on any platform. Other hosted solutions exist:\n ebrains / HBP https://deepnote.com/ on GoogleColab https://colab.research.google.com/github/CONECT-INT/2021-04_PhDProgram-neurosciences-computationnelles/blob/master/MainenSejnowski1995.ipynb    context  The goal of this first task is to create a \u0026ldquo;raster plot\u0026rdquo; that shows the reproducibility of a spike train with repetitions of the same stimulus, as in this work in the rodent retina or in the cat cortex (V1).  Here, we will attempt to replicate Figure 1 of Mainen \u0026amp; Sejnowski (1995):\ngetting to know the tools: numpy and matplotlib  we are going to create vectors representing the dynamics of a value as a function of time for that, we create a vector `time' representing 1 second with a precision of dt=.5ms in a first step, we will create a plot of a spike, a slot \u0026amp; a sinusoid  problem definition: leaky-integrate and fire neuron  we will simulate 1 neuron for 2 seconds with a precision of dt=1ms for that, we use the equation of a leaky-IF then we show its response to the stimuli created above  injection of a noise  As in figure 1 of Mainen \u0026amp; Sejnowski (1995), we add a noise to the current injection this noise can be characterized by its amplitude and its characteristic time: what is the impact on the result? what happens when we include an internal noise to the dynamics of the neuron?  Appendices   an article to read about time in the brain: https://laurentperrinet.github.io/publication/perrinet-19-temps/ direct link\n  From illusions to visual hallucinations: a door on perception - (slides) - article on visual perception: https://laurentperrinet.github.io/post/2019-06-06-theconversation/ direct link\n  Modelling spiking neural networks using Brian, Nest and pyNN - (slides)\n  Tutorial on predictive coding https://laurentperrinet.github.io/talk/2017-06-30-telluride/ https://laurentperrinet.github.io/sciblog/files/2017-06-30_Telluride.html\n ","date":1619136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622103597,"objectID":"5d9538f50f31dbdb637344d695b63e72","permalink":"https://CONECT-INT.github.io/event/2021-04-23-conect-course-phdprogram/","publishdate":"2021-04-23T00:00:00Z","relpermalink":"/event/2021-04-23-conect-course-phdprogram/","section":"event","summary":"Everything You Always Wanted to Know About Computational Models in Neuroscience (But Were Afraid to Ask): a course provided within the NeuroSchool PhD Program.","tags":null,"title":"2021-04-23 : PhDProgram course in computational neuroscience","type":"event"},{"authors":["David Hansel","Laurent U Perrinet"],"categories":null,"content":"Neuroscience is in revolution: Over the past decade, tremendous technological advances across several disciplines have dramatically expanded the frontiers of experimentally accessible neuroscientific facts.\nBridging across different spatial and temporal scales, combination of in vivo two photon imaging, large population recording-array technologies, optogenetic circuit control tools, transgenic manipulations as well as large volume circuit reconstructions are now used to examine the function, structure and dynamics of neural networks on an unprecedented level of detail and precision. Current applications of these novel techniques include sensory information processing, motor production, neural correlates of learning, memory and decision making as well as mechanisms of dysfunctions and disease. These experiments have begun to produce a huge amount of data, on a broad spectrum of temporal and spatial scales, providing finer and more quantitative descriptions of the biological reality than we would have been able to dream of only a decade ago. The daunting complexity of the biological reality revealed by these technologies highlights the importance of neurophysics to provide a conceptual bridge between abstract principles of brain function and their biological implementations within neural circuits. This revolution is accompanied by a parallel revolution in the domain of Artificial Intelligence. An exponential number of algorithms in sensory processing, such as image classification, or reinforcement learning have realized practical tools which have replaced the classical tools we were using on a daily basis by a novel range of intelligent tools of a new generation. This is the context in which we are creating CoNeCt.\nWe are convinced that close collaboration between experimentalists and theoreticians in neuroscience is essential to develop mechanistic as well as quantitative understandings of how the brain performs its functions. This is in fact a primary motivating force in establishing this center. However, for such collaborations to be effective, experimentalists must be well aware of the approaches and challenges in modeling while theoreticians must be well acquainted with the experimental techniques, their power and the challenges they present. CoNeCt has also the ambition to contribute to the training of a new generation of neuroscientists who will have all these qualities.\nThis approach is therefore complementary but distinct in its purpose from neuroinformatics (creation of tools for analyzing neuroscientific data) or artificial intelligence (creation of algorithms inspired by the functioning of the brain). The field of computational neuroscience is still young but its community is now structured in an autonomous community with strong interaction with the other branches of neuroscience. It is this autonomy that we want to foster at INT.\n","date":1618963200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619094007,"objectID":"2cc8f1fda97d726e8b395d9e9522c602","permalink":"https://CONECT-INT.github.io/post/about-conect/","publishdate":"2021-04-21T00:00:00Z","relpermalink":"/post/about-conect/","section":"post","summary":"Neuroscience is in revolution: Over the past decade, tremendous technological advances across several disciplines have dramatically expanded the frontiers of experimentally accessible neuroscientific facts.\n","tags":null,"title":"Objectives of CONECT","type":"post"},{"authors":["David Hansel","Laurent U Perrinet"],"categories":null,"content":"Neuroscience is in revolution: Over the past decade, tremendous technological advances across several disciplines have dramatically expanded the frontiers of experimentally accessible neuroscientific facts.\nBridging across different spatial and temporal scales, combination of in vivo two photon imaging, large population recording-array technologies, optogenetic circuit control tools, transgenic manipulations as well as large volume circuit reconstructions are now used to examine the function, structure and dynamics of neural networks on an unprecedented level of detail and precision. Current applications of these novel techniques include sensory information processing, motor production, neural correlates of learning, memory and decision making as well as mechanisms of dysfunctions and disease. These experiments have begun to produce a huge amount of data, on a broad spectrum of temporal and spatial scales, providing finer and more quantitative descriptions of the biological reality than we would have been able to dream of only a decade ago. The daunting complexity of the biological reality revealed by these technologies highlights the importance of neurophysics to provide a conceptual bridge between abstract principles of brain function and their biological implementations within neural circuits. This revolution is accompanied by a parallel revolution in the domain of Artificial Intelligence. An exponential number of algorithms in sensory processing, such as image classification, or reinforcement learning have realized practical tools which have replaced the classical tools we were using on a daily basis by a novel range of intelligent tools of a new generation. This is the context in which we are creating CoNeCt.\nWe are convinced that close collaboration between experimentalists and theoreticians in neuroscience is essential to develop mechanistic as well as quantitative understandings of how the brain performs its functions. This is in fact a primary motivating force in establishing this center. However, for such collaborations to be effective, experimentalists must be well aware of the approaches and challenges in modeling while theoreticians must be well acquainted with the experimental techniques, their power and the challenges they present. CoNeCt has also the ambition to contribute to the training of a new generation of neuroscientists who will have all these qualities.\nThis approach is therefore complementary but distinct in its purpose from neuroinformatics (creation of tools for analyzing neuroscientific data) or artificial intelligence (creation of algorithms inspired by the functioning of the brain). The field of computational neuroscience is still young but its community is now structured in an autonomous community with strong interaction with the other branches of neuroscience. It is this autonomy that we want to foster at INT.\n","date":1618963200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619094007,"objectID":"97612ea19ee0118357cb0a4f1a8bb4e6","permalink":"https://CONECT-INT.github.io/post/objectives-conect/","publishdate":"2021-04-21T00:00:00Z","relpermalink":"/post/objectives-conect/","section":"post","summary":"Neuroscience is in revolution: Over the past decade, tremendous technological advances across several disciplines have dramatically expanded the frontiers of experimentally accessible neuroscientific facts.\n","tags":null,"title":"Why CONECT ?","type":"post"},{"authors":["Laurent U Perrinet"],"categories":null,"content":"During a seminar at the Institute of Neurosciences Timone in Marseille, Thomas Serre will present his recent work on \u0026ldquo;Feedforward and feedback processes in visual recognition\u0026rdquo;:\n Progress in deep learning has spawned great successes in many engineering applications. As a prime example, convolutional neural networks, a type of feedforward neural networks, are now approaching – and sometimes even surpassing – human accuracy on a variety of visual recognition tasks. In this talk, however, I will show that these neural networks and their recent extensions exhibit a limited ability to solve seemingly simple visual reasoning problems involving incremental grouping, similarity, and spatial relation judgments. Our group has developed a recurrent network model of classical and extra-classical receptive fields that is constrained by the anatomy and physiology of the visual cortex. The model was shown to account for diverse visual illusions providing computational evidence for a novel canonical circuit that is shared across visual modalities. I will show that this computational neuroscience model can be turned into a modern end-to-end trainable deep recurrent network architecture that addresses some of the shortcomings exhibited by state-of-the-art feedforward networks for solving complex visual reasoning tasks. This suggests that neuroscience may contribute powerful new ideas and approaches to computer science and artificial intelligence.\n  Dr. Thomas Serre is an Associate Professor in Cognitive Linguistic \u0026amp; Psychological Sciences and an affiliate of the Carney Institute for Brain Science at Brown University. He received a Ph.D. in Neuroscience from MIT in 2006 and an MSc in EECS from Télécom Bretagne (France) in 2000. His research seeks to understand the neural computations supporting visual perception and has been featured in the BBC series “Visions from the Future” and other news articles (The Economist, New Scientist, Scientific American, IEEE Computing in Science and Technology, Technology Review and Slashdot). Dr. Serre is the Faculty Director of the Center for Computation and Visualization and the Associate Director of the Initiative for Computation in Brain and Mind at Brown University. He also holds an International Chair in AI within the Artificial and Natural Intelligence Toulouse Institute (France). Dr. Serre has served as an area chair and a senior program committee member for top-tier machine learning and computer vision conferences including AAAI, CVPR, and NeurIPS. He is currently serving as a domain expert for IARPA’s Machine Intelligence from Cortical Networks (MICrONS) program and as a scientific advisor for Vium, Inc. He was the recipient of an NSF Early Career Award as well as DARPA’s Young Faculty Award and Director’s Award.   ","date":1592287200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622101941,"objectID":"19085c22ffdbcc99edfc600bed691add","permalink":"https://CONECT-INT.github.io/event/2020-09-11_seminaire-thomas-serre/","publishdate":"2020-06-16T06:00:00Z","relpermalink":"/event/2020-09-11_seminaire-thomas-serre/","section":"event","summary":"A seminar by [Thomas Serre](http://serre-lab.clps.brown.edu/) at the Institute of Neurosciences Timone in Marseille.","tags":["events"],"title":"2020-09-11 : Feedforward and feedback processes in visual recognition (T Serre)","type":"event"},{"authors":["admin"],"categories":null,"content":"toto Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618930757,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://CONECT-INT.github.io/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":["admin","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606937215,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://CONECT-INT.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["admin","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606937215,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://CONECT-INT.github.io/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618839405,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://CONECT-INT.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606937215,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://CONECT-INT.github.io/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"Within INT, many such components already exist, either carried by researchers in computational neurosciences or as themes strongly anchored in this field. A survey of the current situation reveals the existence of projects around different scales:\n  dynamics and function of small and large-scale neural networks (Laurent Perrinet with Frédéric Chavane, David Hansel, Carl van Vreeswijk)\n  Bayesian inference and predictive process models (Anna Montagnini, Emmanuel Daucé and Laurent Perrinet), reinforcement learning, action selection, decision (Andrea Brovelli and Emmanuel Daucé), link with attentional mechanisms (Guilhem Ibos)\n  information theory and functional connectivity for the analysis of cognitive brain networks (Andrea Brovelli and Bruno Giordano)\n  deep learning for data processing in acoustics and semantics (Bruno Giordano), deep learning + neuroimaging (in voice perception) (Charly Lamothe)\n  brain anatomy, particularly as applied to the formation of cortical folding (Julien Lefèvre with Guillaume Auzias, Sylvain Takerkart and Olivier Coulon),\n  the development of prognostic models of the evolution of certain pathologies (Lionel Velly, Sylvain Takerkart),\n  A structuring of these different components through a center (independent of existing and future teams) would be a major asset to reach a new stage in the creation of INT³.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622105010,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://CONECT-INT.github.io/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"Within INT, many such components already exist, either carried by researchers in computational neurosciences or as themes strongly anchored in this field. A survey of the current situation reveals the existence of projects around different scales:","tags":null,"title":"","type":"widget_page"}]